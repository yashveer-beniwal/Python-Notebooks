{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 8 - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have a dataset that describes the actions of potential ad buyers on a social media site. Using this data, can we build a model to predict whether or not a user will purchase an ad?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15624510</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15810944</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15668575</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15603246</td>\n",
       "      <td>Female</td>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15804002</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User ID  Gender  Age  EstimatedSalary  Purchased\n",
       "0  15624510    Male   19            19000          0\n",
       "1  15810944    Male   35            20000          0\n",
       "2  15668575  Female   26            43000          0\n",
       "3  15603246  Female   27            57000          0\n",
       "4  15804002    Male   19            76000          0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad_data = pd.read_csv(\"Social_Network_Ads.csv\")\n",
    "ad_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we use multiple linear regression to build this model? Linear regression requires the residuals to be normally distributed, that unfortunately will not be the case here. Instead of a General Linear Model (like linear regression), we use a Generalied Linear Model. Basically, we need a function to map the space of $(-\\infty, \\infty)$ to $(0,1)$. For that we use the Logit function:\n",
    "$$Logit(p) = log\\bigg(\\frac{p}{1-p}\\bigg)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:2: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEjCAYAAAAypHaFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xt8XWWd7/HPL7emTZpb06RN0jZtKZfeaUOhIJAAKnAQ\nGK84ggJqHRw8enTUUY9n5uV4xtuoOJ5xlBkRHYWqeGMUhSINiNBL2kIvKZTeaNOmadI2l53mvn/n\nj72ptbbNbpK910729/165dW991p7P7+nadd3r2et9Sxzd0RERNKCLkBERJKDAkFERAAFgoiIRCkQ\nREQEUCCIiEiUAkFERAAFgsiIMbN3mdkTQdchMlSm6xAkVZnZXuB97v5knD7fgTnuvjMeny8y0rSH\nICIigAJB5C+Y2fvNbKeZHTWzR82s7KRlbzCzl82szcy+ZWZPm9n7osvuNLNno4+fib7lRTMLmdk7\nAuiKyDlRIIicxMyuAb4AvB2YCrwKrIwuKwYeAT4FTAJeBi4/3ee4+1XRh4vcPdfdfxzn0kWGTYEg\n8ufeBTzg7hvdvYfIxn+5mVUCNwLb3P3n7t4P/CtwKLBKRUaYAkHkz5UR2SsAwN1DwBGgPLps/0nL\nHGhIdIEi8aJAEPlzB4EZrz0xsxwiw0MHgEag4qRldvJzkdFOgSCpLtPMsl/7AR4G7jKzxWY2Dvhn\nYK277wV+Aywws1vNLAP4W2DKWT67CZgV5/pFRowCQVLdY0DXST/VwGeBnxHZI5gN3Abg7i3A24Av\nExlGmgvUAT1n+Ox/BL5vZq1m9va49UBkhOjCNJEhMrM0IscQ3uXuq4OuR2S4tIcgcg7M7I1mVhAd\nTvo0YMCagMsSGREKBJFzsxzYBbQAbwJudfeuYEsSGRkaMhIREUB7CCIiEqVAEBERQIEgIiJRCgQR\nEQEUCCIiEqVAEBERQIEgIiJRCgQREQEUCCIiEqVAEBERQIEgIiJRCgQREQEUCCIiEqVAEBERADKC\nLuBcFBcXe2Vl5ZDe29nZSU5OzsgWlOTU59SgPqeG4fR5w4YNLe4+ebD1RlUgVFZWUldXN6T31tbW\nUl1dPbIFJTn1OTWoz6lhOH02s1djWU9DRiIiAigQREQkSoEgIiKAAkFERKIUCCIiAigQREQkSoEg\nIiLAKLsOQUQk1TS2dfHQ2n2U94Xj3pb2EEREktiBY11886mdtHQpEEREUlpPfyQIMtMs7m0pEERE\nkljviUCIf1sKBBGRJNbTPwBAZrr2EEREUlqP9hBERASgJ3p2UYYCQUQktZ0YMtJBZRGR1KYhIxER\nAU4KhPT4t6VAEBFJYq8FQkb8R4yCDQQzKzCzR8zsJTPbbmbLg6xHRCTZdPX2k52Zhln8EyHouYy+\nAfzO3d9qZlnAhIDrERFJKqGeAXLHJWZTHVggmFk+cBVwJ4C79wK9QdUjIpKMOnv6ExYI5u4Jaegv\nGjZbDNwP1AOLgA3Ah92985T1VgArAEpLS5euXLlySO2FQiFyc3OHVfNooz6nBvV5bPv6hm5ae5yP\nLxwYcp9ramo2uHvVYOsFGQhVwBrgCndfa2bfANrd/bNnek9VVZXX1dUNqb3a2lqqq6uH9N7RSn1O\nDerz2Pb27zyPAfdc0DPkPptZTIEQ5EHlBqDB3ddGnz8CLAmwHhGRpBPqTtyQUWCB4O6HgP1mdkH0\npWuJDB+JiEhUe3cfeeMzE9JW0GcZfQj4UfQMo93AXQHXIyKSVFqP91EwIQUCwd1fAAYd1xIRSUW9\n/WFCPf0UTshKSHu6UllEJEm1dfUBUJigPQQFgohIkmoJ9QBQlDMuIe0pEEREktSh9m4ApuQrEERE\nUlpTWyQQSvOyE9KeAkFEJEk1tUeGjEomKhBERFLaofZuinOzyErE/TNRIIiIJK2m9u6E7R2AAkFE\nJGntO3qcisLxCWtPgSAikoQGws6+I8eZOTknYW0qEEREktDB1i56B8LMnKRAEBFJabtbIreGmVms\nQBARSWmvNHUAMLskcTcCUiCIiCSh+oPtlOaNozg3MVcpgwJBRCQpbTvYzryy/IS2qUAQEUkynT39\n7GwOMa8sL6HtKhBERJLMxn3HGAg7l1QWJbRdBYKISJJZt+co6WnGkhmFCW1XgSAikmTW7TnKvLI8\ncscl9qaWCgQRkSTS0d3Hxn3HWD5rUsLbDjwQzCzdzDaZ2a+DrkVEJGjP7Gihb8C59qLShLcdeCAA\nHwa2B12EiEgyeHJ7E4UTMlkyvSDhbQcaCGZWAfwP4D+DrENEJBkc7+1nVX0T111USkZ64jfPQe8h\n3Ad8AggHXIeISOAe33aIUE8/b1laEUj75u7BNGx2E3Cju3/QzKqBv3P3m06z3gpgBUBpaenSlStX\nDqm9UChEbm7i5gRJBupzalCfx44vr++i+bjzpavGk2b2Z8uG0+eampoN7l416IruHsgP8AWgAdgL\nHAKOAz8823uWLl3qQ7V69eohv3e0Up9Tg/o8Nuw83OGVf/9rv2/VjtMuH06fgTqPYbsc2JCRu3/K\n3SvcvRK4DXjK3W8Pqh4RkSD95x/2kJmexrsumx5YDUEfQxARSXmHO7r52cYG3rq0IqGzm54qsZfB\nnYG71wK1AZchIhKIb/5+J+Gws+LKWYHWoT0EEZEA7WoO8dC6ffz1pdOpTODd0U5HgSAiEhB35wuP\nbSc7I43/ee2coMtRIIiIBOU3Wxp5cvthPnzdnECPHbxGgSAiEoCjnb38w6+2sbAin7uvmBl0OYAC\nQUQk4cJh56M/eYGO7n6+9JaFgUxTcTrJUYWISAr596d3UftyM59901wumprY22SejQJBRCSBnnqp\nia8+8TI3LZzK7ZcGdxHa6SgQREQS5MX9rfztjzYxtyyPL71lIXbKfEVBUyCIiCTAruYQdz+4nkm5\nWTxw5yXkJPj2mLFQIIiIxNnLhzp4x3fWYAbfv3sZJROzgy7ptBQIIiJxtPVAG7fd/zxpBitXLGf2\n5OSdtluBICISJ0+91MQ7vvM84zPT+ckHlnNeSfKGASTJ5HYiImOJu/O9P+7l87+p56KpeXz3PZcw\nJT85h4lOpkAQERlBHd19fOrnW/j15kbeMLeU+25bzISs0bGpHR1VioiMAlsa2rj34Y00HOvi42+8\ngHuunk1aWnKdWno2CgQRkWHq7Q/z7ad38c2nXqE4dxw/XnEZVZVFQZd1zhQIIiLD8OL+Vj75s828\ndKiDNy0q43M3z6MwJyvosoZEgSAiMgStx3u578lX+MHze5k8cRz/8e4qXj+3NOiyhkWBICJyDvoH\nwjy0bh9fW7WD9q4+3rlsOp+84ULysjODLm3YFAgiIjFwdx7fFpmY7pXDIS6fPYnP3pRcs5UOV2CB\nYGbTgB8ApYAD97v7N4KqR0TkdNyd328/zNef3MG2g+3MKs7hO3cs5Q1zS5NucrrhCnIPoR/4mLtv\nNLOJwAYzW+Xu9QHWJCICRG5i8+T2Jv5t9U5ebGhjetEEvvq2RdyyuCxpbmgz0gILBHdvBBqjjzvM\nbDtQDigQRCQw3X0DPLKhgQee3cPulk4qCsfz5bcs5K+WlJM5RoPgNebuQdeAmVUCzwDz3b39lGUr\ngBUApaWlS1euXDmkNkKhELm5yT2PyEhTn1OD+jwyWrvDrN7fz1P7+ujog5n5adxQmcnS0nTSk+Di\nsuH0uaamZoO7Vw22XuCBYGa5wNPA/3X3n59t3aqqKq+rqxtSO7W1tVRXVw/pvaOV+pwa1OehC4ed\nP+xs4aG1r/Lk9sMMhJ3rLirl/VfOZNnMoqQ6RjCcPptZTIEQ6FlGZpYJ/Az40WBhICIyUg53dPPT\nugZWrt/H/qNdFOVk8b7XzeSdy6ZTWZwTdHmBCfIsIwO+C2x3968FVYeIpIbjvf08sa2JX2w6wB9e\naSbscNmsIj7+xgt547xSxmWkB11i4ILcQ7gCuAPYYmYvRF/7tLs/FmBNIjKGDISdP+5s4ZebDvC7\nbYc43jtAecF47qmezZuXVCT1zWqCEORZRs8CyTNAJyJjQt9AmLW7j/LbrY08vq2JllAPE7MzuGVx\nGX91cQVVMwpH1QykiaQrlUVk1OvpH+CPO1v47ZZDrNreROvxPiZkpVNzQQk3LZxKzYUlZGdqSGgw\nCgQRGZVaj/fy9I5mfr/9MKtfOkxHTz8TszO47qJSrp8/havPn6wQOEcKBBEZFdydlw518NRLh/nl\n2i52Pb6KsMOknCxuWDCFGxZM5YrZxWRljO2Lx+JJgSAiSSvU08+aXUd46uXD1L50mINt3QBU5qVx\n7zVzuObCEhaW5+uYwAhRIIhI0ugbCPPC/laefaWFP+5s4YX9rfSHnZysdK6cM5mPXFdC9QWTqd+4\nhurq84Mud8xRIIhIYNydHU0hnt0ZCYC1u4/Q2TtAmsGCigI+cPUsrphdTFVl0Z8NBWnCs/hQIIhI\nwrg7Ow+HWLPnKOv2HOX5XUdoCfUAMLM4h79aUs7rzitm+axi8ieM/hvOjDYxBYKZlRC5kKwM6AK2\nAnXuHo5jbSIyyg2Ene2N7azdc5R1e46wfu8xjnb2AlAycRzLZ0/iyvOKufy8SVQUTgi4WjlrIJhZ\nDfD3QBGwCTgMZAO3ArPN7BHgq6fOUCoiqam3P8yWA63RADjKhr3H6OjpB2B60QSuubCEZTOLuHRm\nEdOLJiTV5HEy+B7CjcD73X3fqQvMLAO4CXg9kQnqRCTFNLV3s/HVY2zcd4yN+1rZcqCN3v7IwMGc\nklxuXlzGsplFLJtZxNT88QFXK4M5ayC4+8fPsqwf+OWIVyQiSam3P0x9Y/uJANi0r5UDrV0AZGWk\nsaA8n/csn8HSGYVcUlnEpNxxAVcs5yrWYwj/Bdzr7m3R55XAd9392viVJiJBamrvZlP0m//GV4+x\n5UAbPdFv/2X52Vw8o5C7XzeTJdMLmFuWp9lCx4BYzzJ6FlhrZh8lcpvLjwMfi1tVIpJQxzp7ebGh\nlS0NbbzY0MbmhlYOd0TO/slKT2N+eR53XDaDJTMKWTK9kCn52QFXLPEQUyC4+3fMbBuwGmgBLnb3\nQ3GtTETiItTTz5boRn/zgcif+492nVg+e3IOV5xXzMKKfBZNK2Cevv2njFiHjO4APgu8G1gIPGZm\nd7n7i/EsTkSGp7tvgPrGdjbvb2VzQxubD7SxqznEa3fOrSgcz8KKfN516QwWVuSzoDyfidk6/z9V\nxTpk9Bbgde5+GHjYzH4BPAhcHK/CROTcdPb0s72xnW0H26k/2M6WA23saOqgPxzZ+hfnjmNRRT5v\nWljGwmn5LCzP14Ff+TOxDhndesrzdWZ2aXxKEpHBtIR6Tmz4V7/QzefqatlzpPPEN//CCZnMK8tn\nxVWzWFhRwKJp+UzJy9Z5/3JWg12Y9r+Bb7n70VOXuXuvmV0DTHD3X8erQJFU5u7sP9pFfWMb2w62\nR3/aaGrvObHOpGxj6axcbllczryyPOaW5TE1Xxt/OXeD7SFsAf7bzLqBjUAzkSuV5xAZLloF/HNc\nKxRJEX0DYXY1h9h24E8b/vrGdjq6I1f6phmcV5LL5bOLIxv+qZGN/wvrnqO6uirg6mUsGOzCtF8B\nvzKzOUTmMpoKtAM/BFa4e9fZ3i8ip3e8t5/tjR3UH/zTN/+XmzpOXOWbnZnGhVPyuHlRGXPL8phX\nls+FUybqDmASV7EeVF7s7g+e/IKZvQ346XAaN7PrgW8A6cB/uvsXh/N5IsnoaGcv26Ib/vroN//d\nLX8a7y+YkMm8sjzes3wG88rymVeWx8ziHDLSdecvSaxYA+FT/OXG/3SvxczM0oF/IzIXUgOw3swe\ndXdNdS6jkrvTcKwrsuFvbD/x7b8xepcvgPKC8Vw0NY+bFpYxryyPeeX5lGm8X5LEYAeVbyAywV25\nmf3rSYvygP5htr0M2Onuu6NtrQRuQfe+kFGgfyDMrubOyMHe6Jh/fWM7bV19QGS8f9bkXJbNLIps\n+MvymTs1j8KcrIArFzkz89f2W0+30GwRsBj4HPB/TlrUAax292NDbtjsrcD17v6+6PM7gEvd/d5T\n1lsBrAAoLS1dunLlyiG1FwqFyM3NHWq5o5L6PDJ6BpyGjjCvtofZ1x7m1Y4wDR1h+qJ3A8lMg4qJ\nacyYmMb0vDRm5KVRMTGNcemJ+dav33NqGE6fa2pqNrj7oGceDHZQ+UXgRTP7UXR204Rz9/uB+wGq\nqqq8urp6SJ9TW1vLUN87WqnP5671eG90nD8y1r/1YDu7mzuJXttFXnYG88oKuXZBHvPKI9/8ZwU8\n3q/fc2pIRJ8HGzL6ibu/HdhkZn+xK+HuC4fR9gFg2knPK6KvicSdu3OovfvPTvHcdrD9xHTOAFPz\ns5lXlseNC6ZGh33yKC8Yr/F+GbMGO6j84eifN8Wh7fXAHDObSSQIbgP+Og7tSIoLh529RzrZdrCd\nrQfbTuwBvHYrRzOYOSmHJTMKuWP5jBPn+GtaB0k1gw0ZNUb/fHWkG3b3fjO7F3icyGmnD7j7tpFu\nR1JLf9jZeqDtxOmd2w62s72xnc7eAQAy043zSydy3UUlJ07xvGhqHjnjYj3hTmTsinW20w7g1CGj\nNqAO+NhrZwqdK3d/DHhsKO8VeW0mzy0NbZHx/gPtvHzoOANPPAtATlY6c8vyeFvVtOjFXXnMKZlI\nVobO7xc5nVi/Ft1H5FqBhwAjMrwzm8h0Fg8A1fEoTuQ1Pf0DvNTYweYDbWxpaGXLgXZ2NHUwED3a\nOykni7lleVxfmckNy+czryyfGUUTSEvTeL9IrGINhJvdfdFJz+83sxfc/ZNm9ul4FCapq7c/zI6m\nDjY3tLHlQBtbDrTy8qEO+gYiG/+inCwWlOdz3UUlLCjPZ0HFn2byrK2tpXphWcA9EBmdYg2E42b2\nduCR6PO3Aq9dfnnmCxlEBtE/EGZHU4itB9rYfCByC8ftjR30DkRO8s8fn8nCinzef+WsExt/nekj\nEh+xBsK7iMw59K3o8+eB281sPHDvGd8lcopDbd28sP8Ym/a1sml/JAC6+iIHfCeOy2B+eT53XVHJ\ngop8FpYXMK1IG3+RRIn1Bjm7gTedYfGzI1eOjCVdvQNsPdjGpn2RAHhhf+uJeX2y0tOYW5bHOy6Z\nxsXTC1hYUaAxf5GAxXqWUQXwTSJTYAP8AfiwuzfEqzAZXdydPS2d0W/+x3hhfyvbG/900Hda0Xgu\nqSxi8bQCLp5ewFzduF0k6cQ6ZPQ9ImcYvS36/Pboa6+PR1GS/PoGwtQfbGf93qOs33uUur3HOBK9\n0Ct3XAaLpuVzz9WzWTytgMXTCyjWRV4iSS/WQJjs7t876fmDZvaReBQkySnU08+mfcdYv/cYdXuP\nsmlf64mx/+lFE6i+oISqykKWzihk9uRc0jX0IzLqxBoIR8zsduDh6PN3AkfiU5Ikg7bjfazZc4Q1\nu4+wfu9R6g+2E/bItM6vjf1fUllEVWUhpXnZQZcrIiMg1kC4m8gxhK8TOc30OeDOONUkAQj19LN+\nz1Ge332E53a1sO1gO+6RWzlePK2Qe2vOo6qyiCUzCsnVNA8iY1KsZxm9Ctx88mvRIaP74lGUxF93\n3wAbXj3Gc7taeH7XEV5saGMg7GSlp3Hx9AI+fO0cLp9dzKJp+Tr4K5IihvNV76MoEEYNd2fn4RBP\n72jm6R3NrN1zlN7+MOlpxqKKfP7m6llcPruYJdMLGZ+lABBJRcMJBB01THLH+5zfbW2MhMDLzRyM\nXgNwXkkut186gyvnFHPJzCINAYkIMLxA0JQVSWh3c4hV9U38fvth6l49Ttg3MnFcBlecV8yHrp3M\nVedPprxgfNBlikgSGuyOaaeb9hoiewfaqiSBcNjZtL+VVfVNrKo/xK7mTgDmTs3jxpmZvPv1VVw8\nvYDMAG/xKCKjw2A3yJmYqEIkdn0DYZ7bdYTfbW1kVf1hWkI9ZKQZl84q4o7LZnDd3FIqCidQW1vL\nsplFQZcrIqOEBo9HiYGws27PUf5780F+u6WRY8f7yMlKp/qCEl4/t5SaC0rIn5AZdJkiMoopEJKY\ne2Q46NEXDvKbLY00d/QwPjOd6+aWctPCqVx9/mSyM3VGkIiMDAVCEjrc3s3PNx3gp3X72dXcSVZG\nGjUXTOZNi8q45sISJmTp1yYiIy+QLYuZfYXIdNq9wC7gLndvDaKWZNHbH+apl5r4SV0DT+9oZiDs\nVM0o5Mtvmc0NC6YwMVvDQSISX0F91VwFfMrd+83sS8CngE8GVEugDrV189DaV3lo3X5aQj2U5o3j\nA1fN4q1LK5g1OTfo8kQkhQQSCO7+xElP1xC5JWfKcHfW7z3G95/fy+NbDzHgzjUXlHD78hlcNWey\nZgoVkUAkw2D03cCPgy4iEcJh54n6Q3yrdhebG9rIy87grisquf2yGcyYlBN0eSKS4sw9Phccm9mT\nwJTTLPqMu/8qus5ngCrgzX6GQsxsBbACoLS0dOnKlSuHVE8oFCI3N5ghmP6w8/zBfh7b00djp1My\nwbihMpPLyzIYlxG/vYEg+xwU9Tk1qM/npqamZoO7Vw22XtwCYdCGze4EPgBc6+7HY3lPVVWV19XV\nDam92tpaqqurh/TeoeofCPPzTQf4xpOvcKC1iwunTOSDNedx4/wpZCTgyuEg+hw09Tk1qM/nxsxi\nCoSgzjK6HvgEcHWsYTCauDtP1DfxlcdfZufhEIsq8vn8rfOpvmAyZjo+ICLJKahjCP8PGAesim4g\n17j73wRUy4ja3NDKPz66jY37Wpk1OYd/f9cSrp8/RUEgIkkvqLOMzgui3Xg61tnLV554mYfX7WNS\nzji++OYFvHVpRUKGhkRERkIynGU0qrk7v9h0gH/6dT3t3f3cdflMPvL6OeTpQjIRGWUUCMPQ3NHD\np3+xhVX1TSydUcjnb53PRVPzgi5LRGRIFAhDtKq+iU888iKdvQN85saLuPt1M3VBmYiMagqEc9Q/\nEOYrj7/Md57ZzfzyPO57x2LOK9FtI0Rk9FMgnIOWUA8f/OFG1u09yu2XTeezN81lXIamnxaRsUGB\nEKNdzSHu/N46mjt6uO8di7n14vKgSxIRGVEKhBjU7T3K+35QR0aasXLFchZPKwi6JBGREadAGMSa\n3Ue463vrmZqfzYN3LWP6pAlBlyQiEhcKhLN4LQzKC8fz8PsvY/LEcUGXJCISN7qM9gzqD7bz3gcV\nBiKSOhQIp9HY1sXdD64nb3wmP3zvpQoDEUkJGjI6RXffAO99sI5QTz8//ZvlTMnPDrokEZGEUCCc\n4nO/rqe+sZ3v3XmJpqEQkZSiIaOT/GZzIw+t3ccHrp5FzYUlQZcjIpJQCoSollBkorrF0wr4uzdc\nEHQ5IiIJp0CI+qdf19PVO8C/vG0hmbqHgYikIG35gOd2tvCrFw5yT/VsTVQnIikr5QPB3fni716i\nvGA891TPDrocEZHApHwg/G7rITY3tPGR6+aQnamZS0UkdaV0IITDztdW7eC8klzevKQi6HJERAIV\naCCY2cfMzM2sOIj2/7CzhVcOh/hg9Wzd7UxEUl5ggWBm04A3APuCquGBZ/cweeI4blpYFlQJIiJJ\nI8g9hK8DnwA8iMZfPdLJ0zuaueOyGWRlpPTImYgIAOae+O2xmd0CXOPuHzazvUCVu7ecYd0VwAqA\n0tLSpStXrhxSm6FQiNzc3BPPf7Wzl1/u7ONfrh7PpPFjMxBO7XMqUJ9Tg/p8bmpqaja4e9WgK7p7\nXH6AJ4Gtp/m5BVgL5EfX2wsUx/KZS5cu9aFavXr1icfhcNhr/mW1v/3bzw3580aDk/ucKtTn1KA+\nnxugzmPYxsZtcjt3v+50r5vZAmAm8KKZAVQAG81smbsfilc9J9t2sJ3dzZ2873WzEtGciMiokPDZ\nTt19C3Bi5rjBhozi4cntTZjB9fOnJKpJEZGkNzYHzwfx9I5mFlUUUJSTFXQpIiJJI/BAcPfKRO4d\nHOvs5cX9rVx9/uRENSkiMioEHgiJtm7vUcIOV84J5Fo4EZGklXKBsGlfK5npxvzy/KBLERFJKikX\nCBv3HWNeWb4mshMROUVKBUL/QJjNDa1cPL0g6FJERJJOSgXCzuYQ3X1hFk9TIIiInCqlAmHX4U4A\n5uiuaCIifyG1AqE5hBnMLM4JuhQRkaSTcoFQXjCe8Vk6oCwicqqUC4TZk1NrhkQRkVilTCCE3dl1\nuJNZkzVcJCJyOikTCO29TlffAJWTFAgiIqeTMoHQ2h25EdCU/OyAKxERSU4pEwjHeqKBkKdAEBE5\nndQJBO0hiIicVeoEQo+TZjBJ90AQETmtlAmE1m5n8sRxZKSnTJdFRM5Jymwd23udSTnjgi5DRCRp\npUwgdPU7eeMTfgtpEZFRI2UC4Xifk5edGXQZIiJJK3UCoR/yxisQRETOJLBAMLMPmdlLZrbNzL4c\n7/a0hyAicnaBDKqbWQ1wC7DI3XvMrCSe7Q2Ene4BmJitYwgiImcS1B7CPcAX3b0HwN0Px7OxUHc/\noCEjEZGzMXdPfKNmLwC/Aq4HuoG/c/f1Z1h3BbACoLS0dOnKlSvPub3m42E+/kwX752fxZUVqRMK\noVCI3NzUmu5bfU4N6vO5qamp2eDuVYOtF7cxFDN7EphymkWfibZbBFwGXAL8xMxm+WnSyd3vB+4H\nqKqq8urq6nOuZeuBNnjmWZZdvIDqeacraWyqra1lKH9fo5n6nBrU5/iIWyC4+3VnWmZm9wA/jwbA\nOjMLA8VAczxqae/uA3QMQUTkbII6hvBLoAbAzM4HsoCWeDXW1TsAwIQsBYKIyJkEtYV8AHjAzLYC\nvcB7TjdcNFJ6+sMAZGemzGUXIiLnLJBAcPde4PZEtdfTH9lDGJeRnqgmRURGnZT4ytwb3UMYl5ES\n3RURGZKU2EL2KBBERAaVElvInr5oIGRqyEhE5ExSIxCixxCydHMcEZEzSoktZE9/GAMy0y3oUkRE\nklbKBEJmGpgpEEREziQ1AqFvAB0+EBE5u5QIhIum5rGkRFcpi4icTUpsJW9bNp0px3cHXYaISFJL\niT0EEREZnAJBREQABYKIiEQpEEREBFAgiIhIlAJBREQABYKIiEQpEEREBACL450rR5yZNQOvDvHt\nxcTxvs0ABjPgAAAEh0lEQVRJSn1ODepzahhOn2e4++TBVhpVgTAcZlbn7lVB15FI6nNqUJ9TQyL6\nrCEjEREBFAgiIhKVSoFwf9AFBEB9Tg3qc2qIe59T5hiCiIicXSrtIYiIyFmMuUAws+vN7GUz22lm\nf3+a5ePM7MfR5WvNrDLxVY6sGPr8UTOrN7PNZvZ7M5sRRJ0jabA+n7TeW8zMzWzUn5ESS5/N7O3R\n3/U2M3so0TWOtBj+bU83s9Vmtin67/vGIOocKWb2gJkdNrOtZ1huZvav0b+PzWa2ZEQLcPcx8wOk\nA7uAWUAW8CIw95R1Pgh8O/r4NuDHQdedgD7XABOij+9JhT5H15sIPAOsAaqCrjsBv+c5wCagMPq8\nJOi6E9Dn+4F7oo/nAnuDrnuYfb4KWAJsPcPyG4HfAgZcBqwdyfbH2h7CMmCnu+92915gJXDLKevc\nAnw/+vgR4FozswTWONIG7bO7r3b349Gna4CKBNc40mL5PQP8E/AloDuRxcVJLH1+P/Bv7n4MwN0P\nJ7jGkRZLnx3Iiz7OBw4msL4R5+7PAEfPssotwA88Yg1QYGZTR6r9sRYI5cD+k543RF877Tru3g+0\nAZMSUl18xNLnk72XyDeM0WzQPkd3pae5+28SWVgcxfJ7Ph8438z+aGZrzOz6hFUXH7H0+R+B282s\nAXgM+FBiSgvMuf5/PycpcU9liTCz24Eq4Oqga4knM0sDvgbcGXApiZZBZNiomshe4DNmtsDdWwOt\nKr7eCTzo7l81s+XAf5nZfHcPB13YaDTW9hAOANNOel4Rfe2065hZBpHdzCMJqS4+YukzZnYd8Bng\nZnfvSVBt8TJYnycC84FaM9tLZKz10VF+YDmW33MD8Ki797n7HmAHkYAYrWLp83uBnwC4+/NANpE5\nf8aqmP6/D9VYC4T1wBwzm2lmWUQOGj96yjqPAu+JPn4r8JRHj9aMUoP22cwuBr5DJAxG+7gyDNJn\nd29z92J3r3T3SiLHTW5297pgyh0Rsfzb/iWRvQPMrJjIENLuRBY5wmLp8z7gWgAzu4hIIDQntMrE\nehR4d/Rso8uANndvHKkPH1NDRu7eb2b3Ao8TOUPhAXffZmafA+rc/VHgu0R2K3cSOXhzW3AVD1+M\nff4KkAv8NHr8fJ+73xxY0cMUY5/HlBj7/DjwBjOrBwaAj7v7qN37jbHPHwP+w8z+F5EDzHeO5i94\nZvYwkVAvjh4X+QcgE8Ddv03kOMmNwE7gOHDXiLY/iv/uRERkBI21ISMRERkiBYKIiAAKBBERiVIg\niIgIoEAQEZEoBYKIiAAKBBERiVIgiAyDmV0SnZc+28xyovchmB90XSJDoQvTRIbJzD5PZMqE8UCD\nu38h4JJEhkSBIDJM0Xl21hO578Ll7j4QcEkiQ6IhI5Hhm0RkrqiJRPYUREYl7SGIDJOZPUrkbl4z\nganufm/AJYkMyZia7VQk0czs3UCfuz9kZunAc2Z2jbs/FXRtIudKewgiIgLoGIKIiEQpEEREBFAg\niIhIlAJBREQABYKIiEQpEEREBFAgiIhIlAJBREQA+P8cFiQun+VjZQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1102015f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def logit(p):\n",
    "    return np.log(p / (1 - p))\n",
    "\n",
    "x = np.arange(0, 1, 0.001)\n",
    "logit_vals = logit(x)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, logit_vals)\n",
    "ax.grid(True)\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"Logit(x)\")\n",
    "fig.suptitle(\"Logit\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As written, this function maps our data from $(0,1)$ to $(-\\infty, \\infty)$. We actually want the opposite, so we reverse the equation:\n",
    "$$f(x) = \\frac{1}{1+e^{-x}}$$\n",
    "This is known as the sigmoid function. We can use it to see the relationship between the probability (p) and the logit function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEjCAYAAADdZh27AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFEREpMn/B2xz6l0Z2IWJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110c9c4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "x = np.arange(-5., 5., 0.1)\n",
    "sig = sigmoid(x)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.plot(x,sig)\n",
    "ax.grid(True)\n",
    "ax.set_xlabel(\"logit(p)\")\n",
    "ax.set_ylabel(\"p\")\n",
    "fig.suptitle(\"The Sigmoid Function\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this in the same way that we used our multiple regression equation:\n",
    "$$logit(p_{i}) = log\\bigg(\\frac{p_{i}}{1-p_{i}}\\bigg) = \\beta_{0} + \\beta_{1}x_{1} + \\beta_{1}x_{1} + ... + \\beta_{k}x_{k}$$\n",
    "\n",
    "We can use this equation to solve for $p_{i}$, when we do this is the equation:\n",
    "$$p_{i} = \\frac{e^{(\\beta_{0} + \\beta_{1} \\cdot x_{1} + ... + \\beta_{n} \\cdot x_{n}) }}{1 + e^{(\\beta_{0} + \\beta_{1} \\cdot x_{1} + ... + \\beta_{n} \\cdot x_{n}) }}$$\n",
    "\n",
    "This equation is applied in logistic regression, a machine learning algorithm used for binary predictions. Here we apply this equation to solve the question above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.93245089]\n",
      "[[-0.09186917  2.07997332  1.11053785]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = ad_data[[\"Gender\", \"Age\", \"EstimatedSalary\"]]\n",
    "X[\"Gender\"] = pd.get_dummies(X[\"Gender\"])[\"Female\"]\n",
    "Y = ad_data[\"Purchased\"]\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "X_Train, X_Test, Y_Train, Y_Test = train_test_split(X, Y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Feature Scaling - This is not necessary, but it is highly recommended.\n",
    "sc_X = StandardScaler()\n",
    "X_Train = sc_X.fit_transform(X_Train)\n",
    "X_Test = sc_X.transform(X_Test)\n",
    "\n",
    "# Fitting the Logistic Regression into the Training set\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_Train, Y_Train)\n",
    "\n",
    "print(classifier.intercept_)\n",
    "print(classifier.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the predictions, we can begin evaluating our classifier. We'll begin by looking at the values we can determine from the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Probabilities</th>\n",
       "      <th>Y_Predictions</th>\n",
       "      <th>Y_Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.124345</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>0.157210</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>0.212761</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.083687</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>0.091364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.008774</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.014092</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>0.753855</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.005382</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>0.533229</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.040101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.027173</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.176484</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>0.396509</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.017226</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.319129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>0.303222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.013625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.987853</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.046759</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.083656</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>0.960884</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.263281</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>0.893727</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.004163</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>0.971159</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.072584</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.084456</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>0.182613</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.147303</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.575605</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>0.193450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.010392</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.277878</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.075476</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.010104</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>0.519626</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>0.279854</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>0.710016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>0.881844</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>0.996498</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.976086</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.012105</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.009623</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>0.886369</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>0.527657</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.386460</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>0.995531</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.420422</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>0.323179</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>0.445060</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>0.769570</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.007897</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.008832</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.036110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.078431</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.015269</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>0.504279</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>0.864409</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>0.744077</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Probabilities  Y_Predictions  Y_Values\n",
       "132       0.124345              0         0\n",
       "309       0.157210              0         0\n",
       "341       0.212761              0         0\n",
       "196       0.083687              0         0\n",
       "246       0.091364              0         0\n",
       "60        0.008774              0         0\n",
       "155       0.014092              0         0\n",
       "261       0.753855              1         1\n",
       "141       0.005382              0         0\n",
       "214       0.533229              1         0\n",
       "37        0.040101              0         0\n",
       "134       0.027173              0         0\n",
       "113       0.176484              0         0\n",
       "348       0.396509              0         0\n",
       "12        0.017226              0         0\n",
       "59        0.319129              0         0\n",
       "293       0.303222              0         0\n",
       "140       0.013625              0         0\n",
       "206       0.987853              1         1\n",
       "199       0.046759              0         0\n",
       "176       0.083656              0         0\n",
       "268       0.960884              1         1\n",
       "124       0.263281              0         0\n",
       "344       0.893727              1         1\n",
       "175       0.004163              0         0\n",
       "313       0.971159              1         1\n",
       "78        0.072584              0         0\n",
       "15        0.084456              0         0\n",
       "286       0.182613              0         0\n",
       "102       0.147303              0         0\n",
       "..             ...            ...       ...\n",
       "7         0.575605              1         1\n",
       "260       0.193450              0         0\n",
       "68        0.010392              0         0\n",
       "20        0.277878              0         1\n",
       "107       0.075476              0         0\n",
       "14        0.010104              0         0\n",
       "363       0.519626              1         0\n",
       "304       0.279854              0         0\n",
       "361       0.710016              1         1\n",
       "329       0.881844              1         1\n",
       "336       0.996498              1         1\n",
       "64        0.976086              1         0\n",
       "55        0.012105              0         0\n",
       "106       0.009623              0         0\n",
       "300       0.886369              1         1\n",
       "229       0.527657              1         1\n",
       "122       0.386460              0         0\n",
       "373       0.995531              1         1\n",
       "395       0.420422              0         1\n",
       "325       0.323179              0         0\n",
       "380       0.445060              0         0\n",
       "253       0.769570              1         1\n",
       "56        0.007897              0         0\n",
       "8         0.008832              0         0\n",
       "190       0.036110              0         0\n",
       "146       0.078431              0         1\n",
       "135       0.015269              0         0\n",
       "390       0.504279              1         1\n",
       "264       0.864409              1         1\n",
       "364       0.744077              1         1\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_Probs = classifier.predict_proba(X_Test)\n",
    "Y_Pred = classifier.predict(X_Test)\n",
    "\n",
    "pred_df = pd.DataFrame({\"Probabilities\": Y_Probs[:,1], \"Y_Predictions\": Y_Pred, \"Y_Values\": Y_Test})\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 True Positivies\n",
      "3 False Positivies\n",
      "65 True Negatives\n",
      "6 False Negatives\n",
      "Accuracy is: 0.91\n",
      "Precision is: 0.90\n",
      "Sensitivity is: 0.81\n",
      "Specificity is: 0.96\n"
     ]
    }
   ],
   "source": [
    "TP = sum((pred_df[\"Y_Predictions\"] == 1) & (pred_df[\"Y_Values\"] == 1))\n",
    "FP = sum((pred_df[\"Y_Predictions\"] == 1) & (pred_df[\"Y_Values\"] == 0))\n",
    "TN = sum((pred_df[\"Y_Predictions\"] == 0) & (pred_df[\"Y_Values\"] == 0))\n",
    "FN = sum((pred_df[\"Y_Predictions\"] == 0) & (pred_df[\"Y_Values\"] == 1))\n",
    "accuracy = (TP + TN) / (TP + FP + TN + FN)\n",
    "precision = TP / (TP + FP)\n",
    "sensitivity = TP / (TP + FN)\n",
    "specificity = TN / (TN + FP)\n",
    "\n",
    "print(\"%s True Positivies\" % TP)\n",
    "print(\"%s False Positivies\" % FP)\n",
    "print(\"%s True Negatives\" % TN)\n",
    "print(\"%s False Negatives\" % FN)\n",
    "print(\"Accuracy is: %.2f\" % accuracy)\n",
    "print(\"Precision is: %.2f\" % precision)\n",
    "print(\"Sensitivity is: %.2f\" % sensitivity)\n",
    "print(\"Specificity is: %.2f\" % specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the cutoff used to go from a probability to a prediction is 0.5, but this is not necessarily optimal. How do our results change if we alter the cutoff?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_df[\"Y_Predictions_2\"] = (pred_df[\"Probabilities\"] >= 0.3).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 True Positivies\n",
      "12 False Positivies\n",
      "56 True Negatives\n",
      "2 False Negatives\n",
      "Accuracy is: 0.86\n",
      "Precision is: 0.71\n",
      "Sensitivity is: 0.94\n",
      "Specificity is: 0.82\n"
     ]
    }
   ],
   "source": [
    "TP = sum((pred_df[\"Y_Predictions_2\"] == 1) & (pred_df[\"Y_Values\"] == 1))\n",
    "FP = sum((pred_df[\"Y_Predictions_2\"] == 1) & (pred_df[\"Y_Values\"] == 0))\n",
    "TN = sum((pred_df[\"Y_Predictions_2\"] == 0) & (pred_df[\"Y_Values\"] == 0))\n",
    "FN = sum((pred_df[\"Y_Predictions_2\"] == 0) & (pred_df[\"Y_Values\"] == 1))\n",
    "accuracy = (TP + TN) / (TP + FP + TN + FN)\n",
    "precision = TP / (TP + FP)\n",
    "sensitivity = TP / (TP + FN)\n",
    "specificity = TN / (TN + FP)\n",
    "\n",
    "print(\"%s True Positivies\" % TP)\n",
    "print(\"%s False Positivies\" % FP)\n",
    "print(\"%s True Negatives\" % TN)\n",
    "print(\"%s False Negatives\" % FN)\n",
    "print(\"Accuracy is: %.2f\" % accuracy)\n",
    "print(\"Precision is: %.2f\" % precision)\n",
    "print(\"Sensitivity is: %.2f\" % sensitivity)\n",
    "print(\"Specificity is: %.2f\" % specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In determining where to place the cutoff, it can often be useful to look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "histnorm": "probability",
         "name": "Didn't Purchase",
         "opacity": 0.75,
         "type": "histogram",
         "x": [
          0.12434513619179015,
          0.15720992341756299,
          0.2127606433012784,
          0.08368733953920107,
          0.09136431601878056,
          0.00877417858149029,
          0.01409199063297638,
          0.005382201233485571,
          0.5332292762862273,
          0.040100709138709285,
          0.027172788397962538,
          0.17648362555703018,
          0.3965093805516699,
          0.01722610006953265,
          0.3191289560371162,
          0.3032224126915741,
          0.013624925185448038,
          0.04675914765337962,
          0.08365565477551294,
          0.2632810111833933,
          0.004163370605294189,
          0.07258418581394226,
          0.08445649766416014,
          0.18261284559480956,
          0.14730267631055438,
          0.02245407873010601,
          0.16731860201960422,
          0.015960342105150727,
          0.0038698824875394084,
          0.02203214166751376,
          0.06131476265776687,
          0.025675810632992884,
          0.07325945519693369,
          0.3072491338303097,
          0.05466925635224543,
          0.04397117906754141,
          0.02442592722728665,
          0.2851248349322767,
          0.009842699267870514,
          0.03529696679634552,
          0.11187767975658604,
          0.4436332144030088,
          0.07795498919941624,
          0.03973374645485911,
          0.003868289741442602,
          0.02271832684810144,
          0.010232332379763797,
          0.0017167707481551828,
          0.03532512141055751,
          0.029209807758824455,
          0.23505473692372897,
          0.4473858878582798,
          0.1934504894422172,
          0.010391582351454728,
          0.0754757174471349,
          0.010103542641499357,
          0.5196257644771021,
          0.2798537494831195,
          0.9760856331039557,
          0.012105354068780947,
          0.009623101081631127,
          0.38645992339209095,
          0.32317850972138895,
          0.44505991177399773,
          0.007897356019217526,
          0.008831809442467056,
          0.03610985223378691,
          0.01526885235480943
         ]
        },
        {
         "histnorm": "probability",
         "name": "Purchased",
         "opacity": 0.75,
         "type": "histogram",
         "x": [
          0.7538552857042717,
          0.987852840461723,
          0.9608844693915466,
          0.8937269249769794,
          0.9711594849311362,
          0.3169976974507822,
          0.9393645250218088,
          0.5339280872824169,
          0.7936487756362989,
          0.9236190009110739,
          0.8732046422977364,
          0.9895724681660373,
          0.9795690302907636,
          0.3468230417409325,
          0.5155231207228095,
          0.9415146227349546,
          0.4183310205852912,
          0.9836787343864468,
          0.5756047018162714,
          0.2778777372403819,
          0.7100162631539968,
          0.8818439794877128,
          0.9964980896398076,
          0.8863690211830276,
          0.5276570898273801,
          0.9955311764591429,
          0.42042177773416567,
          0.7695702337256757,
          0.07843106162394595,
          0.5042793750858818,
          0.8644089960655004,
          0.744077037673382
         ]
        }
       ],
       "layout": {
        "barmode": "overlay",
        "xaxis": {
         "title": "Prediction Confidence"
        },
        "yaxis": {
         "title": "Frequency"
        }
       }
      },
      "text/html": [
       "<div id=\"c230f779-19da-4e85-bf0e-babdee1fe94f\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"c230f779-19da-4e85-bf0e-babdee1fe94f\", [{\"type\": \"histogram\", \"x\": [0.12434513619179015, 0.15720992341756299, 0.2127606433012784, 0.08368733953920107, 0.09136431601878056, 0.00877417858149029, 0.01409199063297638, 0.005382201233485571, 0.5332292762862273, 0.040100709138709285, 0.027172788397962538, 0.17648362555703018, 0.3965093805516699, 0.01722610006953265, 0.3191289560371162, 0.3032224126915741, 0.013624925185448038, 0.04675914765337962, 0.08365565477551294, 0.2632810111833933, 0.004163370605294189, 0.07258418581394226, 0.08445649766416014, 0.18261284559480956, 0.14730267631055438, 0.02245407873010601, 0.16731860201960422, 0.015960342105150727, 0.0038698824875394084, 0.02203214166751376, 0.06131476265776687, 0.025675810632992884, 0.07325945519693369, 0.3072491338303097, 0.05466925635224543, 0.04397117906754141, 0.02442592722728665, 0.2851248349322767, 0.009842699267870514, 0.03529696679634552, 0.11187767975658604, 0.4436332144030088, 0.07795498919941624, 0.03973374645485911, 0.003868289741442602, 0.02271832684810144, 0.010232332379763797, 0.0017167707481551828, 0.03532512141055751, 0.029209807758824455, 0.23505473692372897, 0.4473858878582798, 0.1934504894422172, 0.010391582351454728, 0.0754757174471349, 0.010103542641499357, 0.5196257644771021, 0.2798537494831195, 0.9760856331039557, 0.012105354068780947, 0.009623101081631127, 0.38645992339209095, 0.32317850972138895, 0.44505991177399773, 0.007897356019217526, 0.008831809442467056, 0.03610985223378691, 0.01526885235480943], \"opacity\": 0.75, \"name\": \"Didn't Purchase\", \"histnorm\": \"probability\"}, {\"type\": \"histogram\", \"x\": [0.7538552857042717, 0.987852840461723, 0.9608844693915466, 0.8937269249769794, 0.9711594849311362, 0.3169976974507822, 0.9393645250218088, 0.5339280872824169, 0.7936487756362989, 0.9236190009110739, 0.8732046422977364, 0.9895724681660373, 0.9795690302907636, 0.3468230417409325, 0.5155231207228095, 0.9415146227349546, 0.4183310205852912, 0.9836787343864468, 0.5756047018162714, 0.2778777372403819, 0.7100162631539968, 0.8818439794877128, 0.9964980896398076, 0.8863690211830276, 0.5276570898273801, 0.9955311764591429, 0.42042177773416567, 0.7695702337256757, 0.07843106162394595, 0.5042793750858818, 0.8644089960655004, 0.744077037673382], \"opacity\": 0.75, \"name\": \"Purchased\", \"histnorm\": \"probability\"}], {\"barmode\": \"overlay\", \"xaxis\": {\"title\": \"Prediction Confidence\"}, \"yaxis\": {\"title\": \"Frequency\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"c230f779-19da-4e85-bf0e-babdee1fe94f\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"c230f779-19da-4e85-bf0e-babdee1fe94f\", [{\"type\": \"histogram\", \"x\": [0.12434513619179015, 0.15720992341756299, 0.2127606433012784, 0.08368733953920107, 0.09136431601878056, 0.00877417858149029, 0.01409199063297638, 0.005382201233485571, 0.5332292762862273, 0.040100709138709285, 0.027172788397962538, 0.17648362555703018, 0.3965093805516699, 0.01722610006953265, 0.3191289560371162, 0.3032224126915741, 0.013624925185448038, 0.04675914765337962, 0.08365565477551294, 0.2632810111833933, 0.004163370605294189, 0.07258418581394226, 0.08445649766416014, 0.18261284559480956, 0.14730267631055438, 0.02245407873010601, 0.16731860201960422, 0.015960342105150727, 0.0038698824875394084, 0.02203214166751376, 0.06131476265776687, 0.025675810632992884, 0.07325945519693369, 0.3072491338303097, 0.05466925635224543, 0.04397117906754141, 0.02442592722728665, 0.2851248349322767, 0.009842699267870514, 0.03529696679634552, 0.11187767975658604, 0.4436332144030088, 0.07795498919941624, 0.03973374645485911, 0.003868289741442602, 0.02271832684810144, 0.010232332379763797, 0.0017167707481551828, 0.03532512141055751, 0.029209807758824455, 0.23505473692372897, 0.4473858878582798, 0.1934504894422172, 0.010391582351454728, 0.0754757174471349, 0.010103542641499357, 0.5196257644771021, 0.2798537494831195, 0.9760856331039557, 0.012105354068780947, 0.009623101081631127, 0.38645992339209095, 0.32317850972138895, 0.44505991177399773, 0.007897356019217526, 0.008831809442467056, 0.03610985223378691, 0.01526885235480943], \"opacity\": 0.75, \"name\": \"Didn't Purchase\", \"histnorm\": \"probability\"}, {\"type\": \"histogram\", \"x\": [0.7538552857042717, 0.987852840461723, 0.9608844693915466, 0.8937269249769794, 0.9711594849311362, 0.3169976974507822, 0.9393645250218088, 0.5339280872824169, 0.7936487756362989, 0.9236190009110739, 0.8732046422977364, 0.9895724681660373, 0.9795690302907636, 0.3468230417409325, 0.5155231207228095, 0.9415146227349546, 0.4183310205852912, 0.9836787343864468, 0.5756047018162714, 0.2778777372403819, 0.7100162631539968, 0.8818439794877128, 0.9964980896398076, 0.8863690211830276, 0.5276570898273801, 0.9955311764591429, 0.42042177773416567, 0.7695702337256757, 0.07843106162394595, 0.5042793750858818, 0.8644089960655004, 0.744077037673382], \"opacity\": 0.75, \"name\": \"Purchased\", \"histnorm\": \"probability\"}], {\"barmode\": \"overlay\", \"xaxis\": {\"title\": \"Prediction Confidence\"}, \"yaxis\": {\"title\": \"Frequency\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "group_0 = pred_df[pred_df[\"Y_Values\"] == 0][\"Probabilities\"]\n",
    "group_1 = pred_df[pred_df[\"Y_Values\"] == 1][\"Probabilities\"]\n",
    "\n",
    "trace1 = go.Histogram(\n",
    "    x=group_0,\n",
    "    opacity=0.75,\n",
    "    name=\"Didn't Purchase\",\n",
    "    histnorm=\"probability\"\n",
    ")\n",
    "trace2 = go.Histogram(\n",
    "    x=group_1,\n",
    "    opacity=0.75,\n",
    "    name=\"Purchased\",\n",
    "    histnorm=\"probability\"    \n",
    ")\n",
    "data = [trace1, trace2]\n",
    "\n",
    "layout = go.Layout(\n",
    "    barmode='overlay',\n",
    "    xaxis=dict(title=\"Prediction Confidence\"),\n",
    "    yaxis=dict(title=\"Frequency\")\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also generate evaluation criteria that tell us how well our classifier worked. First we'll make a Receiver Operating Characteristic (ROC) curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "mode": "lines",
         "name": "Predictor",
         "type": "scatter",
         "x": [
          0,
          0,
          0.014705882352941176,
          0.014705882352941176,
          0.029411764705882353,
          0.029411764705882353,
          0.04411764705882353,
          0.04411764705882353,
          0.08823529411764706,
          0.08823529411764706,
          0.11764705882352941,
          0.11764705882352941,
          0.14705882352941177,
          0.14705882352941177,
          0.20588235294117646,
          0.20588235294117646,
          0.4264705882352941,
          0.4264705882352941,
          1
         ],
         "y": [
          0.03125,
          0.1875,
          0.1875,
          0.71875,
          0.71875,
          0.75,
          0.75,
          0.8125,
          0.8125,
          0.875,
          0.875,
          0.90625,
          0.90625,
          0.9375,
          0.9375,
          0.96875,
          0.96875,
          1,
          1
         ]
        },
        {
         "line": {
          "color": "grey",
          "dash": "dash"
         },
         "mode": "lines",
         "name": "Random",
         "type": "scatter",
         "x": [
          0,
          0,
          0.014705882352941176,
          0.014705882352941176,
          0.029411764705882353,
          0.029411764705882353,
          0.04411764705882353,
          0.04411764705882353,
          0.08823529411764706,
          0.08823529411764706,
          0.11764705882352941,
          0.11764705882352941,
          0.14705882352941177,
          0.14705882352941177,
          0.20588235294117646,
          0.20588235294117646,
          0.4264705882352941,
          0.4264705882352941,
          1
         ],
         "y": [
          0,
          0,
          0.014705882352941176,
          0.014705882352941176,
          0.029411764705882353,
          0.029411764705882353,
          0.04411764705882353,
          0.04411764705882353,
          0.08823529411764706,
          0.08823529411764706,
          0.11764705882352941,
          0.11764705882352941,
          0.14705882352941177,
          0.14705882352941177,
          0.20588235294117646,
          0.20588235294117646,
          0.4264705882352941,
          0.4264705882352941,
          1
         ]
        }
       ],
       "layout": {
        "title": "ROC Curve for Ad Purchases",
        "xaxis": {
         "title": "False Positive Rate"
        },
        "yaxis": {
         "title": "True Positive Rate"
        }
       }
      },
      "text/html": [
       "<div id=\"8e61c371-3b82-45d0-878c-ca476e0b7edc\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"8e61c371-3b82-45d0-878c-ca476e0b7edc\", [{\"type\": \"scatter\", \"x\": [0.0, 0.0, 0.014705882352941176, 0.014705882352941176, 0.029411764705882353, 0.029411764705882353, 0.04411764705882353, 0.04411764705882353, 0.08823529411764706, 0.08823529411764706, 0.11764705882352941, 0.11764705882352941, 0.14705882352941177, 0.14705882352941177, 0.20588235294117646, 0.20588235294117646, 0.4264705882352941, 0.4264705882352941, 1.0], \"y\": [0.03125, 0.1875, 0.1875, 0.71875, 0.71875, 0.75, 0.75, 0.8125, 0.8125, 0.875, 0.875, 0.90625, 0.90625, 0.9375, 0.9375, 0.96875, 0.96875, 1.0, 1.0], \"mode\": \"lines\", \"name\": \"Predictor\"}, {\"type\": \"scatter\", \"x\": [0.0, 0.0, 0.014705882352941176, 0.014705882352941176, 0.029411764705882353, 0.029411764705882353, 0.04411764705882353, 0.04411764705882353, 0.08823529411764706, 0.08823529411764706, 0.11764705882352941, 0.11764705882352941, 0.14705882352941177, 0.14705882352941177, 0.20588235294117646, 0.20588235294117646, 0.4264705882352941, 0.4264705882352941, 1.0], \"y\": [0.0, 0.0, 0.014705882352941176, 0.014705882352941176, 0.029411764705882353, 0.029411764705882353, 0.04411764705882353, 0.04411764705882353, 0.08823529411764706, 0.08823529411764706, 0.11764705882352941, 0.11764705882352941, 0.14705882352941177, 0.14705882352941177, 0.20588235294117646, 0.20588235294117646, 0.4264705882352941, 0.4264705882352941, 1.0], \"mode\": \"lines\", \"name\": \"Random\", \"line\": {\"dash\": \"dash\", \"color\": \"grey\"}}], {\"title\": \"ROC Curve for Ad Purchases\", \"xaxis\": {\"title\": \"False Positive Rate\"}, \"yaxis\": {\"title\": \"True Positive Rate\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"8e61c371-3b82-45d0-878c-ca476e0b7edc\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"8e61c371-3b82-45d0-878c-ca476e0b7edc\", [{\"type\": \"scatter\", \"x\": [0.0, 0.0, 0.014705882352941176, 0.014705882352941176, 0.029411764705882353, 0.029411764705882353, 0.04411764705882353, 0.04411764705882353, 0.08823529411764706, 0.08823529411764706, 0.11764705882352941, 0.11764705882352941, 0.14705882352941177, 0.14705882352941177, 0.20588235294117646, 0.20588235294117646, 0.4264705882352941, 0.4264705882352941, 1.0], \"y\": [0.03125, 0.1875, 0.1875, 0.71875, 0.71875, 0.75, 0.75, 0.8125, 0.8125, 0.875, 0.875, 0.90625, 0.90625, 0.9375, 0.9375, 0.96875, 0.96875, 1.0, 1.0], \"mode\": \"lines\", \"name\": \"Predictor\"}, {\"type\": \"scatter\", \"x\": [0.0, 0.0, 0.014705882352941176, 0.014705882352941176, 0.029411764705882353, 0.029411764705882353, 0.04411764705882353, 0.04411764705882353, 0.08823529411764706, 0.08823529411764706, 0.11764705882352941, 0.11764705882352941, 0.14705882352941177, 0.14705882352941177, 0.20588235294117646, 0.20588235294117646, 0.4264705882352941, 0.4264705882352941, 1.0], \"y\": [0.0, 0.0, 0.014705882352941176, 0.014705882352941176, 0.029411764705882353, 0.029411764705882353, 0.04411764705882353, 0.04411764705882353, 0.08823529411764706, 0.08823529411764706, 0.11764705882352941, 0.11764705882352941, 0.14705882352941177, 0.14705882352941177, 0.20588235294117646, 0.20588235294117646, 0.4264705882352941, 0.4264705882352941, 1.0], \"mode\": \"lines\", \"name\": \"Random\", \"line\": {\"dash\": \"dash\", \"color\": \"grey\"}}], {\"title\": \"ROC Curve for Ad Purchases\", \"xaxis\": {\"title\": \"False Positive Rate\"}, \"yaxis\": {\"title\": \"True Positive Rate\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under the ROC Curve (AUC) is 0.95\n"
     ]
    }
   ],
   "source": [
    "# Use sklearn to get us the tpr and fpr at different cutoffs\n",
    "tpr, fpr, _ = metrics.roc_curve(pred_df[\"Y_Values\"], pred_df[\"Probabilities\"])\n",
    "\n",
    "trace0 = go.Scatter(\n",
    "    x = tpr,\n",
    "    y = fpr,\n",
    "    mode = 'lines',\n",
    "    name = 'Predictor'\n",
    ")\n",
    "\n",
    "trace1 = go.Scatter(\n",
    "    x = tpr,\n",
    "    y = tpr,\n",
    "    mode='lines',\n",
    "    name='Random',\n",
    "    line=dict(\n",
    "        dash=\"dash\",\n",
    "        color=\"grey\")\n",
    ")\n",
    "\n",
    "data = [trace0, trace1]\n",
    "\n",
    "layout = dict(title = 'ROC Curve for Ad Purchases',\n",
    "              xaxis = dict(title = 'False Positive Rate'),\n",
    "              yaxis = dict(title = 'True Positive Rate'),\n",
    "              )\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "iplot(fig)\n",
    "auc = metrics.roc_auc_score(pred_df[\"Y_Values\"], pred_df[\"Probabilities\"])\n",
    "print(\"Area Under the ROC Curve (AUC) is %.2f\" % auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up is a precision-recall plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "mode": "lines",
         "name": "Predictor",
         "type": "scatter",
         "x": [
          1,
          0.96875,
          0.96875,
          0.96875,
          0.96875,
          0.96875,
          0.96875,
          0.96875,
          0.96875,
          0.96875,
          0.96875,
          0.96875,
          0.96875,
          0.96875,
          0.96875,
          0.96875,
          0.96875,
          0.9375,
          0.9375,
          0.9375,
          0.9375,
          0.9375,
          0.90625,
          0.90625,
          0.90625,
          0.875,
          0.875,
          0.875,
          0.84375,
          0.8125,
          0.8125,
          0.8125,
          0.8125,
          0.78125,
          0.75,
          0.75,
          0.71875,
          0.71875,
          0.6875,
          0.65625,
          0.625,
          0.59375,
          0.5625,
          0.53125,
          0.5,
          0.46875,
          0.4375,
          0.40625,
          0.375,
          0.34375,
          0.3125,
          0.28125,
          0.25,
          0.21875,
          0.1875,
          0.1875,
          0.15625,
          0.125,
          0.09375,
          0.0625,
          0.03125,
          0
         ],
         "y": [
          0.5245901639344263,
          0.5166666666666667,
          0.5254237288135594,
          0.5344827586206896,
          0.543859649122807,
          0.5535714285714286,
          0.5636363636363636,
          0.5740740740740741,
          0.5849056603773585,
          0.5961538461538461,
          0.6078431372549019,
          0.62,
          0.6326530612244898,
          0.6458333333333334,
          0.6595744680851063,
          0.6739130434782609,
          0.6888888888888889,
          0.6818181818181818,
          0.6976744186046512,
          0.7142857142857143,
          0.7317073170731707,
          0.75,
          0.7435897435897436,
          0.7631578947368421,
          0.7837837837837838,
          0.7777777777777778,
          0.8,
          0.8235294117647058,
          0.8181818181818182,
          0.8125,
          0.8387096774193549,
          0.8666666666666667,
          0.896551724137931,
          0.8928571428571429,
          0.8888888888888888,
          0.9230769230769231,
          0.92,
          0.9583333333333334,
          0.9565217391304348,
          0.9545454545454546,
          0.9523809523809523,
          0.95,
          0.9473684210526315,
          0.9444444444444444,
          0.9411764705882353,
          0.9375,
          0.9333333333333333,
          0.9285714285714286,
          0.9230769230769231,
          0.9166666666666666,
          0.9090909090909091,
          0.9,
          0.8888888888888888,
          0.875,
          0.8571428571428571,
          1,
          1,
          1,
          1,
          1,
          1,
          1
         ]
        }
       ],
       "layout": {
        "title": "Precision-Recall Curve for Ad Purchases",
        "xaxis": {
         "title": "Recall"
        },
        "yaxis": {
         "title": "Precision"
        }
       }
      },
      "text/html": [
       "<div id=\"7d6d9150-eb8e-42d0-9501-62aac24d6b0a\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"7d6d9150-eb8e-42d0-9501-62aac24d6b0a\", [{\"type\": \"scatter\", \"x\": [1.0, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.90625, 0.90625, 0.90625, 0.875, 0.875, 0.875, 0.84375, 0.8125, 0.8125, 0.8125, 0.8125, 0.78125, 0.75, 0.75, 0.71875, 0.71875, 0.6875, 0.65625, 0.625, 0.59375, 0.5625, 0.53125, 0.5, 0.46875, 0.4375, 0.40625, 0.375, 0.34375, 0.3125, 0.28125, 0.25, 0.21875, 0.1875, 0.1875, 0.15625, 0.125, 0.09375, 0.0625, 0.03125, 0.0], \"y\": [0.5245901639344263, 0.5166666666666667, 0.5254237288135594, 0.5344827586206896, 0.543859649122807, 0.5535714285714286, 0.5636363636363636, 0.5740740740740741, 0.5849056603773585, 0.5961538461538461, 0.6078431372549019, 0.62, 0.6326530612244898, 0.6458333333333334, 0.6595744680851063, 0.6739130434782609, 0.6888888888888889, 0.6818181818181818, 0.6976744186046512, 0.7142857142857143, 0.7317073170731707, 0.75, 0.7435897435897436, 0.7631578947368421, 0.7837837837837838, 0.7777777777777778, 0.8, 0.8235294117647058, 0.8181818181818182, 0.8125, 0.8387096774193549, 0.8666666666666667, 0.896551724137931, 0.8928571428571429, 0.8888888888888888, 0.9230769230769231, 0.92, 0.9583333333333334, 0.9565217391304348, 0.9545454545454546, 0.9523809523809523, 0.95, 0.9473684210526315, 0.9444444444444444, 0.9411764705882353, 0.9375, 0.9333333333333333, 0.9285714285714286, 0.9230769230769231, 0.9166666666666666, 0.9090909090909091, 0.9, 0.8888888888888888, 0.875, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], \"mode\": \"lines\", \"name\": \"Predictor\"}], {\"title\": \"Precision-Recall Curve for Ad Purchases\", \"xaxis\": {\"title\": \"Recall\"}, \"yaxis\": {\"title\": \"Precision\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"7d6d9150-eb8e-42d0-9501-62aac24d6b0a\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"7d6d9150-eb8e-42d0-9501-62aac24d6b0a\", [{\"type\": \"scatter\", \"x\": [1.0, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.90625, 0.90625, 0.90625, 0.875, 0.875, 0.875, 0.84375, 0.8125, 0.8125, 0.8125, 0.8125, 0.78125, 0.75, 0.75, 0.71875, 0.71875, 0.6875, 0.65625, 0.625, 0.59375, 0.5625, 0.53125, 0.5, 0.46875, 0.4375, 0.40625, 0.375, 0.34375, 0.3125, 0.28125, 0.25, 0.21875, 0.1875, 0.1875, 0.15625, 0.125, 0.09375, 0.0625, 0.03125, 0.0], \"y\": [0.5245901639344263, 0.5166666666666667, 0.5254237288135594, 0.5344827586206896, 0.543859649122807, 0.5535714285714286, 0.5636363636363636, 0.5740740740740741, 0.5849056603773585, 0.5961538461538461, 0.6078431372549019, 0.62, 0.6326530612244898, 0.6458333333333334, 0.6595744680851063, 0.6739130434782609, 0.6888888888888889, 0.6818181818181818, 0.6976744186046512, 0.7142857142857143, 0.7317073170731707, 0.75, 0.7435897435897436, 0.7631578947368421, 0.7837837837837838, 0.7777777777777778, 0.8, 0.8235294117647058, 0.8181818181818182, 0.8125, 0.8387096774193549, 0.8666666666666667, 0.896551724137931, 0.8928571428571429, 0.8888888888888888, 0.9230769230769231, 0.92, 0.9583333333333334, 0.9565217391304348, 0.9545454545454546, 0.9523809523809523, 0.95, 0.9473684210526315, 0.9444444444444444, 0.9411764705882353, 0.9375, 0.9333333333333333, 0.9285714285714286, 0.9230769230769231, 0.9166666666666666, 0.9090909090909091, 0.9, 0.8888888888888888, 0.875, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], \"mode\": \"lines\", \"name\": \"Predictor\"}], {\"title\": \"Precision-Recall Curve for Ad Purchases\", \"xaxis\": {\"title\": \"Recall\"}, \"yaxis\": {\"title\": \"Precision\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use sklearn to get us the tpr and fpr at different cutoffs\n",
    "precision, recall, _ = metrics.precision_recall_curve(pred_df[\"Y_Values\"], pred_df[\"Probabilities\"])\n",
    "\n",
    "trace0 = go.Scatter(\n",
    "    x = recall,\n",
    "    y = precision,\n",
    "    mode = 'lines',\n",
    "    name = 'Predictor'\n",
    ")\n",
    "\n",
    "data = [trace0]\n",
    "\n",
    "layout = dict(title = 'Precision-Recall Curve for Ad Purchases',\n",
    "              xaxis = dict(title = 'Recall'),\n",
    "              yaxis = dict(title = 'Precision'),\n",
    "              )\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "iplot(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
