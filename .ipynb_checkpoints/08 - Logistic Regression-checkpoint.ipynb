{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 8 - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have a dataset that describes the actions of potential ad buyers on a social media site. Using this data, can we build a model to predict whether or not a user will purchase an ad?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15624510</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15810944</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15668575</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15603246</td>\n",
       "      <td>Female</td>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15804002</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User ID  Gender  Age  EstimatedSalary  Purchased\n",
       "0  15624510    Male   19            19000          0\n",
       "1  15810944    Male   35            20000          0\n",
       "2  15668575  Female   26            43000          0\n",
       "3  15603246  Female   27            57000          0\n",
       "4  15804002    Male   19            76000          0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad_data = pd.read_csv(\"Social_Network_Ads.csv\")\n",
    "ad_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we use multiple linear regression to build this model? Linear regression requires the residuals to be normally distributed, that unfortunately will not be the case here. Instead of a General Linear Model (like linear regression), we use a Generalied Linear Model. Basically, we need a function to map the space of $(-\\infty, \\infty)$ to $(0,1)$. For that we use the Logit function:\n",
    "$$Logit(p) = log\\bigg(\\frac{p}{1-p}\\bigg)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEjCAYAAAAypHaFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQUREAAWCiIhEKBBERASA/w8bISxF8kMrBQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107da39e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def logit(p):\n",
    "    return np.log(p / (1 - p))\n",
    "\n",
    "x = np.arange(0, 1, 0.001)\n",
    "logit_vals = logit(x)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, logit_vals)\n",
    "ax.grid(True)\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"Logit(x)\")\n",
    "fig.suptitle(\"Logit\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As written, this function maps our data from $(0,1)$ to $(-\\infty, \\infty)$. We actually want the opposite, so we reverse the equation:\n",
    "$$f(x) = \\frac{1}{1+e^{-x}}$$\n",
    "This is known as the sigmoid function. We can use it to see the relationship between the probability (p) and the logit function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEjCAYAAADdZh27AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11194b3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "x = np.arange(-5., 5., 0.1)\n",
    "sig = sigmoid(x)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.plot(x,sig)\n",
    "ax.grid(True)\n",
    "ax.set_xlabel(\"logit(p)\")\n",
    "ax.set_ylabel(\"p\")\n",
    "fig.suptitle(\"The Sigmoid Function\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this in the same way that we used our multiple regression equation:\n",
    "$$logit(p_{i}) = log\\bigg(\\frac{p_{i}}{1-p_{i}}\\bigg) = \\beta_{0} + \\beta_{1}x_{1} + \\beta_{1}x_{1} + ... + \\beta_{k}x_{k}$$\n",
    "\n",
    "We can use this equation to solve for $p_{i}$, when we do this is the equation:\n",
    "$$p_{i} = \\frac{e^{(\\beta_{0} + \\beta_{1} \\cdot x_{1} + ... + \\beta_{n} \\cdot x_{n}) }}{1 + e^{(\\beta_{0} + \\beta_{1} \\cdot x_{1} + ... + \\beta_{n} \\cdot x_{n}) }}$$\n",
    "\n",
    "This equation is applied in logistic regression, a machine learning algorithm used for binary predictions. Here we apply this equation to solve the question above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.93245089]\n",
      "[[-0.09186917  2.07997332  1.11053785]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = ad_data[[\"Gender\", \"Age\", \"EstimatedSalary\"]]\n",
    "X[\"Gender\"] = pd.get_dummies(X[\"Gender\"])[\"Female\"]\n",
    "Y = ad_data[\"Purchased\"]\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "X_Train, X_Test, Y_Train, Y_Test = train_test_split(X, Y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Feature Scaling - This is not necessary, but it is highly recommended.\n",
    "sc_X = StandardScaler()\n",
    "X_Train = sc_X.fit_transform(X_Train)\n",
    "X_Test = sc_X.transform(X_Test)\n",
    "\n",
    "# Fitting the Logistic Regression into the Training set\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_Train, Y_Train)\n",
    "\n",
    "print(classifier.intercept_)\n",
    "print(classifier.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the predictions, we can begin evaluating our classifier. We'll begin by looking at the values we can determine from the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Probabilities</th>\n",
       "      <th>Y_Predictions</th>\n",
       "      <th>Y_Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.124345</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>0.157210</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>0.212761</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.083687</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>0.091364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.008774</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.014092</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>0.753855</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.005382</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>0.533229</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.040101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.027173</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.176484</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>0.396509</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.017226</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.319129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>0.303222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.013625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.987853</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.046759</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.083656</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>0.960884</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.263281</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>0.893727</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.004163</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>0.971159</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.072584</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.084456</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>0.182613</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.147303</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.575605</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>0.193450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.010392</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.277878</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.075476</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.010104</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>0.519626</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>0.279854</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>0.710016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>0.881844</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>0.996498</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.976086</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.012105</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.009623</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>0.886369</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>0.527657</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.386460</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>0.995531</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.420422</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>0.323179</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>0.445060</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>0.769570</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.007897</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.008832</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.036110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.078431</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.015269</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>0.504279</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>0.864409</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>0.744077</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Probabilities  Y_Predictions  Y_Values\n",
       "132       0.124345              0         0\n",
       "309       0.157210              0         0\n",
       "341       0.212761              0         0\n",
       "196       0.083687              0         0\n",
       "246       0.091364              0         0\n",
       "60        0.008774              0         0\n",
       "155       0.014092              0         0\n",
       "261       0.753855              1         1\n",
       "141       0.005382              0         0\n",
       "214       0.533229              1         0\n",
       "37        0.040101              0         0\n",
       "134       0.027173              0         0\n",
       "113       0.176484              0         0\n",
       "348       0.396509              0         0\n",
       "12        0.017226              0         0\n",
       "59        0.319129              0         0\n",
       "293       0.303222              0         0\n",
       "140       0.013625              0         0\n",
       "206       0.987853              1         1\n",
       "199       0.046759              0         0\n",
       "176       0.083656              0         0\n",
       "268       0.960884              1         1\n",
       "124       0.263281              0         0\n",
       "344       0.893727              1         1\n",
       "175       0.004163              0         0\n",
       "313       0.971159              1         1\n",
       "78        0.072584              0         0\n",
       "15        0.084456              0         0\n",
       "286       0.182613              0         0\n",
       "102       0.147303              0         0\n",
       "..             ...            ...       ...\n",
       "7         0.575605              1         1\n",
       "260       0.193450              0         0\n",
       "68        0.010392              0         0\n",
       "20        0.277878              0         1\n",
       "107       0.075476              0         0\n",
       "14        0.010104              0         0\n",
       "363       0.519626              1         0\n",
       "304       0.279854              0         0\n",
       "361       0.710016              1         1\n",
       "329       0.881844              1         1\n",
       "336       0.996498              1         1\n",
       "64        0.976086              1         0\n",
       "55        0.012105              0         0\n",
       "106       0.009623              0         0\n",
       "300       0.886369              1         1\n",
       "229       0.527657              1         1\n",
       "122       0.386460              0         0\n",
       "373       0.995531              1         1\n",
       "395       0.420422              0         1\n",
       "325       0.323179              0         0\n",
       "380       0.445060              0         0\n",
       "253       0.769570              1         1\n",
       "56        0.007897              0         0\n",
       "8         0.008832              0         0\n",
       "190       0.036110              0         0\n",
       "146       0.078431              0         1\n",
       "135       0.015269              0         0\n",
       "390       0.504279              1         1\n",
       "264       0.864409              1         1\n",
       "364       0.744077              1         1\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_Probs = classifier.predict_proba(X_Test)\n",
    "Y_Pred = classifier.predict(X_Test)\n",
    "\n",
    "pred_df = pd.DataFrame({\"Probabilities\": Y_Probs[:,1], \"Y_Predictions\": Y_Pred, \"Y_Values\": Y_Test})\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 True Positivies\n",
      "3 False Positivies\n",
      "65 True Negatives\n",
      "6 False Negatives\n",
      "Accuracy is: 0.91\n",
      "Precision is: 0.90\n",
      "Sensitivity is: 0.81\n",
      "Specificity is: 0.96\n"
     ]
    }
   ],
   "source": [
    "TP = sum((pred_df[\"Y_Predictions\"] == 1) & (pred_df[\"Y_Values\"] == 1))\n",
    "FP = sum((pred_df[\"Y_Predictions\"] == 1) & (pred_df[\"Y_Values\"] == 0))\n",
    "TN = sum((pred_df[\"Y_Predictions\"] == 0) & (pred_df[\"Y_Values\"] == 0))\n",
    "FN = sum((pred_df[\"Y_Predictions\"] == 0) & (pred_df[\"Y_Values\"] == 1))\n",
    "accuracy = (TP + TN) / (TP + FP + TN + FN)\n",
    "precision = TP / (TP + FP)\n",
    "sensitivity = TP / (TP + FN)\n",
    "specificity = TN / (TN + FP)\n",
    "\n",
    "print(\"%s True Positivies\" % TP)\n",
    "print(\"%s False Positivies\" % FP)\n",
    "print(\"%s True Negatives\" % TN)\n",
    "print(\"%s False Negatives\" % FN)\n",
    "print(\"Accuracy is: %.2f\" % accuracy)\n",
    "print(\"Precision is: %.2f\" % precision)\n",
    "print(\"Sensitivity is: %.2f\" % sensitivity)\n",
    "print(\"Specificity is: %.2f\" % specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the cutoff used to go from a probability to a prediction is 0.5, but this is not necessarily optimal. How do our results change if we alter the cutoff?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_df[\"Y_Predictions_2\"] = (pred_df[\"Probabilities\"] >= 0.3).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 True Positivies\n",
      "12 False Positivies\n",
      "56 True Negatives\n",
      "2 False Negatives\n",
      "Accuracy is: 0.86\n",
      "Precision is: 0.71\n",
      "Sensitivity is: 0.94\n",
      "Specificity is: 0.82\n"
     ]
    }
   ],
   "source": [
    "TP = sum((pred_df[\"Y_Predictions_2\"] == 1) & (pred_df[\"Y_Values\"] == 1))\n",
    "FP = sum((pred_df[\"Y_Predictions_2\"] == 1) & (pred_df[\"Y_Values\"] == 0))\n",
    "TN = sum((pred_df[\"Y_Predictions_2\"] == 0) & (pred_df[\"Y_Values\"] == 0))\n",
    "FN = sum((pred_df[\"Y_Predictions_2\"] == 0) & (pred_df[\"Y_Values\"] == 1))\n",
    "accuracy = (TP + TN) / (TP + FP + TN + FN)\n",
    "precision = TP / (TP + FP)\n",
    "sensitivity = TP / (TP + FN)\n",
    "specificity = TN / (TN + FP)\n",
    "\n",
    "print(\"%s True Positivies\" % TP)\n",
    "print(\"%s False Positivies\" % FP)\n",
    "print(\"%s True Negatives\" % TN)\n",
    "print(\"%s False Negatives\" % FN)\n",
    "print(\"Accuracy is: %.2f\" % accuracy)\n",
    "print(\"Precision is: %.2f\" % precision)\n",
    "print(\"Sensitivity is: %.2f\" % sensitivity)\n",
    "print(\"Specificity is: %.2f\" % specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In determining where to place the cutoff, it can often be useful to look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "histnorm": "probability",
         "name": "Didn't Purchase",
         "opacity": 0.75,
         "type": "histogram",
         "x": [
          0.12434513619179015,
          0.15720992341756299,
          0.2127606433012784,
          0.08368733953920107,
          0.09136431601878056,
          0.00877417858149029,
          0.01409199063297638,
          0.005382201233485571,
          0.5332292762862273,
          0.040100709138709285,
          0.027172788397962538,
          0.17648362555703018,
          0.3965093805516699,
          0.01722610006953265,
          0.3191289560371162,
          0.3032224126915741,
          0.013624925185448038,
          0.04675914765337962,
          0.08365565477551294,
          0.2632810111833933,
          0.004163370605294189,
          0.07258418581394226,
          0.08445649766416014,
          0.18261284559480956,
          0.14730267631055438,
          0.02245407873010601,
          0.16731860201960422,
          0.015960342105150727,
          0.0038698824875394084,
          0.02203214166751376,
          0.06131476265776687,
          0.025675810632992884,
          0.07325945519693369,
          0.3072491338303097,
          0.05466925635224543,
          0.04397117906754141,
          0.02442592722728665,
          0.2851248349322767,
          0.009842699267870514,
          0.03529696679634552,
          0.11187767975658604,
          0.4436332144030088,
          0.07795498919941624,
          0.03973374645485911,
          0.003868289741442602,
          0.02271832684810144,
          0.010232332379763797,
          0.0017167707481551828,
          0.03532512141055751,
          0.029209807758824455,
          0.23505473692372897,
          0.4473858878582798,
          0.1934504894422172,
          0.010391582351454728,
          0.0754757174471349,
          0.010103542641499357,
          0.5196257644771021,
          0.2798537494831195,
          0.9760856331039557,
          0.012105354068780947,
          0.009623101081631127,
          0.38645992339209095,
          0.32317850972138895,
          0.44505991177399773,
          0.007897356019217526,
          0.008831809442467056,
          0.03610985223378691,
          0.01526885235480943
         ]
        },
        {
         "histnorm": "probability",
         "name": "Purchased",
         "opacity": 0.75,
         "type": "histogram",
         "x": [
          0.7538552857042717,
          0.987852840461723,
          0.9608844693915466,
          0.8937269249769794,
          0.9711594849311362,
          0.3169976974507822,
          0.9393645250218088,
          0.5339280872824169,
          0.7936487756362989,
          0.9236190009110739,
          0.8732046422977364,
          0.9895724681660373,
          0.9795690302907636,
          0.3468230417409325,
          0.5155231207228095,
          0.9415146227349546,
          0.4183310205852912,
          0.9836787343864468,
          0.5756047018162714,
          0.2778777372403819,
          0.7100162631539968,
          0.8818439794877128,
          0.9964980896398076,
          0.8863690211830276,
          0.5276570898273801,
          0.9955311764591429,
          0.42042177773416567,
          0.7695702337256757,
          0.07843106162394595,
          0.5042793750858818,
          0.8644089960655004,
          0.744077037673382
         ]
        }
       ],
       "layout": {
        "barmode": "overlay",
        "xaxis": {
         "title": "Prediction Confidence"
        },
        "yaxis": {
         "title": "Frequency"
        }
       }
      },
      "text/html": [
       "<div id=\"73e56f4f-41a3-4d7e-ab59-1067d47529ed\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"73e56f4f-41a3-4d7e-ab59-1067d47529ed\", [{\"type\": \"histogram\", \"x\": [0.12434513619179015, 0.15720992341756299, 0.2127606433012784, 0.08368733953920107, 0.09136431601878056, 0.00877417858149029, 0.01409199063297638, 0.005382201233485571, 0.5332292762862273, 0.040100709138709285, 0.027172788397962538, 0.17648362555703018, 0.3965093805516699, 0.01722610006953265, 0.3191289560371162, 0.3032224126915741, 0.013624925185448038, 0.04675914765337962, 0.08365565477551294, 0.2632810111833933, 0.004163370605294189, 0.07258418581394226, 0.08445649766416014, 0.18261284559480956, 0.14730267631055438, 0.02245407873010601, 0.16731860201960422, 0.015960342105150727, 0.0038698824875394084, 0.02203214166751376, 0.06131476265776687, 0.025675810632992884, 0.07325945519693369, 0.3072491338303097, 0.05466925635224543, 0.04397117906754141, 0.02442592722728665, 0.2851248349322767, 0.009842699267870514, 0.03529696679634552, 0.11187767975658604, 0.4436332144030088, 0.07795498919941624, 0.03973374645485911, 0.003868289741442602, 0.02271832684810144, 0.010232332379763797, 0.0017167707481551828, 0.03532512141055751, 0.029209807758824455, 0.23505473692372897, 0.4473858878582798, 0.1934504894422172, 0.010391582351454728, 0.0754757174471349, 0.010103542641499357, 0.5196257644771021, 0.2798537494831195, 0.9760856331039557, 0.012105354068780947, 0.009623101081631127, 0.38645992339209095, 0.32317850972138895, 0.44505991177399773, 0.007897356019217526, 0.008831809442467056, 0.03610985223378691, 0.01526885235480943], \"opacity\": 0.75, \"name\": \"Didn't Purchase\", \"histnorm\": \"probability\"}, {\"type\": \"histogram\", \"x\": [0.7538552857042717, 0.987852840461723, 0.9608844693915466, 0.8937269249769794, 0.9711594849311362, 0.3169976974507822, 0.9393645250218088, 0.5339280872824169, 0.7936487756362989, 0.9236190009110739, 0.8732046422977364, 0.9895724681660373, 0.9795690302907636, 0.3468230417409325, 0.5155231207228095, 0.9415146227349546, 0.4183310205852912, 0.9836787343864468, 0.5756047018162714, 0.2778777372403819, 0.7100162631539968, 0.8818439794877128, 0.9964980896398076, 0.8863690211830276, 0.5276570898273801, 0.9955311764591429, 0.42042177773416567, 0.7695702337256757, 0.07843106162394595, 0.5042793750858818, 0.8644089960655004, 0.744077037673382], \"opacity\": 0.75, \"name\": \"Purchased\", \"histnorm\": \"probability\"}], {\"barmode\": \"overlay\", \"xaxis\": {\"title\": \"Prediction Confidence\"}, \"yaxis\": {\"title\": \"Frequency\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"73e56f4f-41a3-4d7e-ab59-1067d47529ed\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"73e56f4f-41a3-4d7e-ab59-1067d47529ed\", [{\"type\": \"histogram\", \"x\": [0.12434513619179015, 0.15720992341756299, 0.2127606433012784, 0.08368733953920107, 0.09136431601878056, 0.00877417858149029, 0.01409199063297638, 0.005382201233485571, 0.5332292762862273, 0.040100709138709285, 0.027172788397962538, 0.17648362555703018, 0.3965093805516699, 0.01722610006953265, 0.3191289560371162, 0.3032224126915741, 0.013624925185448038, 0.04675914765337962, 0.08365565477551294, 0.2632810111833933, 0.004163370605294189, 0.07258418581394226, 0.08445649766416014, 0.18261284559480956, 0.14730267631055438, 0.02245407873010601, 0.16731860201960422, 0.015960342105150727, 0.0038698824875394084, 0.02203214166751376, 0.06131476265776687, 0.025675810632992884, 0.07325945519693369, 0.3072491338303097, 0.05466925635224543, 0.04397117906754141, 0.02442592722728665, 0.2851248349322767, 0.009842699267870514, 0.03529696679634552, 0.11187767975658604, 0.4436332144030088, 0.07795498919941624, 0.03973374645485911, 0.003868289741442602, 0.02271832684810144, 0.010232332379763797, 0.0017167707481551828, 0.03532512141055751, 0.029209807758824455, 0.23505473692372897, 0.4473858878582798, 0.1934504894422172, 0.010391582351454728, 0.0754757174471349, 0.010103542641499357, 0.5196257644771021, 0.2798537494831195, 0.9760856331039557, 0.012105354068780947, 0.009623101081631127, 0.38645992339209095, 0.32317850972138895, 0.44505991177399773, 0.007897356019217526, 0.008831809442467056, 0.03610985223378691, 0.01526885235480943], \"opacity\": 0.75, \"name\": \"Didn't Purchase\", \"histnorm\": \"probability\"}, {\"type\": \"histogram\", \"x\": [0.7538552857042717, 0.987852840461723, 0.9608844693915466, 0.8937269249769794, 0.9711594849311362, 0.3169976974507822, 0.9393645250218088, 0.5339280872824169, 0.7936487756362989, 0.9236190009110739, 0.8732046422977364, 0.9895724681660373, 0.9795690302907636, 0.3468230417409325, 0.5155231207228095, 0.9415146227349546, 0.4183310205852912, 0.9836787343864468, 0.5756047018162714, 0.2778777372403819, 0.7100162631539968, 0.8818439794877128, 0.9964980896398076, 0.8863690211830276, 0.5276570898273801, 0.9955311764591429, 0.42042177773416567, 0.7695702337256757, 0.07843106162394595, 0.5042793750858818, 0.8644089960655004, 0.744077037673382], \"opacity\": 0.75, \"name\": \"Purchased\", \"histnorm\": \"probability\"}], {\"barmode\": \"overlay\", \"xaxis\": {\"title\": \"Prediction Confidence\"}, \"yaxis\": {\"title\": \"Frequency\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "group_0 = pred_df[pred_df[\"Y_Values\"] == 0][\"Probabilities\"]\n",
    "group_1 = pred_df[pred_df[\"Y_Values\"] == 1][\"Probabilities\"]\n",
    "\n",
    "trace1 = go.Histogram(\n",
    "    x=group_0,\n",
    "    opacity=0.75,\n",
    "    name=\"Didn't Purchase\",\n",
    "    histnorm=\"probability\"\n",
    ")\n",
    "trace2 = go.Histogram(\n",
    "    x=group_1,\n",
    "    opacity=0.75,\n",
    "    name=\"Purchased\",\n",
    "    histnorm=\"probability\"    \n",
    ")\n",
    "data = [trace1, trace2]\n",
    "\n",
    "layout = go.Layout(\n",
    "    barmode='overlay',\n",
    "    xaxis=dict(title=\"Prediction Confidence\"),\n",
    "    yaxis=dict(title=\"Frequency\")\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also generate evaluation criteria that tell us how well our classifier worked. First we'll make a Receiver Operating Characteristic (ROC) curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "mode": "lines",
         "name": "Predictor",
         "type": "scatter",
         "x": [
          0,
          0,
          0.014705882352941176,
          0.014705882352941176,
          0.029411764705882353,
          0.029411764705882353,
          0.04411764705882353,
          0.04411764705882353,
          0.08823529411764706,
          0.08823529411764706,
          0.11764705882352941,
          0.11764705882352941,
          0.14705882352941177,
          0.14705882352941177,
          0.20588235294117646,
          0.20588235294117646,
          0.4264705882352941,
          0.4264705882352941,
          1
         ],
         "y": [
          0.03125,
          0.1875,
          0.1875,
          0.71875,
          0.71875,
          0.75,
          0.75,
          0.8125,
          0.8125,
          0.875,
          0.875,
          0.90625,
          0.90625,
          0.9375,
          0.9375,
          0.96875,
          0.96875,
          1,
          1
         ]
        },
        {
         "line": {
          "color": "grey",
          "dash": "dash"
         },
         "mode": "lines",
         "name": "Random",
         "type": "scatter",
         "x": [
          0,
          0,
          0.014705882352941176,
          0.014705882352941176,
          0.029411764705882353,
          0.029411764705882353,
          0.04411764705882353,
          0.04411764705882353,
          0.08823529411764706,
          0.08823529411764706,
          0.11764705882352941,
          0.11764705882352941,
          0.14705882352941177,
          0.14705882352941177,
          0.20588235294117646,
          0.20588235294117646,
          0.4264705882352941,
          0.4264705882352941,
          1
         ],
         "y": [
          0,
          0,
          0.014705882352941176,
          0.014705882352941176,
          0.029411764705882353,
          0.029411764705882353,
          0.04411764705882353,
          0.04411764705882353,
          0.08823529411764706,
          0.08823529411764706,
          0.11764705882352941,
          0.11764705882352941,
          0.14705882352941177,
          0.14705882352941177,
          0.20588235294117646,
          0.20588235294117646,
          0.4264705882352941,
          0.4264705882352941,
          1
         ]
        }
       ],
       "layout": {
        "title": "ROC Curve for Ad Purchases",
        "xaxis": {
         "title": "False Positive Rate"
        },
        "yaxis": {
         "title": "True Positive Rate"
        }
       }
      },
      "text/html": [
       "<div id=\"8e61c371-3b82-45d0-878c-ca476e0b7edc\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"8e61c371-3b82-45d0-878c-ca476e0b7edc\", [{\"type\": \"scatter\", \"x\": [0.0, 0.0, 0.014705882352941176, 0.014705882352941176, 0.029411764705882353, 0.029411764705882353, 0.04411764705882353, 0.04411764705882353, 0.08823529411764706, 0.08823529411764706, 0.11764705882352941, 0.11764705882352941, 0.14705882352941177, 0.14705882352941177, 0.20588235294117646, 0.20588235294117646, 0.4264705882352941, 0.4264705882352941, 1.0], \"y\": [0.03125, 0.1875, 0.1875, 0.71875, 0.71875, 0.75, 0.75, 0.8125, 0.8125, 0.875, 0.875, 0.90625, 0.90625, 0.9375, 0.9375, 0.96875, 0.96875, 1.0, 1.0], \"mode\": \"lines\", \"name\": \"Predictor\"}, {\"type\": \"scatter\", \"x\": [0.0, 0.0, 0.014705882352941176, 0.014705882352941176, 0.029411764705882353, 0.029411764705882353, 0.04411764705882353, 0.04411764705882353, 0.08823529411764706, 0.08823529411764706, 0.11764705882352941, 0.11764705882352941, 0.14705882352941177, 0.14705882352941177, 0.20588235294117646, 0.20588235294117646, 0.4264705882352941, 0.4264705882352941, 1.0], \"y\": [0.0, 0.0, 0.014705882352941176, 0.014705882352941176, 0.029411764705882353, 0.029411764705882353, 0.04411764705882353, 0.04411764705882353, 0.08823529411764706, 0.08823529411764706, 0.11764705882352941, 0.11764705882352941, 0.14705882352941177, 0.14705882352941177, 0.20588235294117646, 0.20588235294117646, 0.4264705882352941, 0.4264705882352941, 1.0], \"mode\": \"lines\", \"name\": \"Random\", \"line\": {\"dash\": \"dash\", \"color\": \"grey\"}}], {\"title\": \"ROC Curve for Ad Purchases\", \"xaxis\": {\"title\": \"False Positive Rate\"}, \"yaxis\": {\"title\": \"True Positive Rate\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"8e61c371-3b82-45d0-878c-ca476e0b7edc\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"8e61c371-3b82-45d0-878c-ca476e0b7edc\", [{\"type\": \"scatter\", \"x\": [0.0, 0.0, 0.014705882352941176, 0.014705882352941176, 0.029411764705882353, 0.029411764705882353, 0.04411764705882353, 0.04411764705882353, 0.08823529411764706, 0.08823529411764706, 0.11764705882352941, 0.11764705882352941, 0.14705882352941177, 0.14705882352941177, 0.20588235294117646, 0.20588235294117646, 0.4264705882352941, 0.4264705882352941, 1.0], \"y\": [0.03125, 0.1875, 0.1875, 0.71875, 0.71875, 0.75, 0.75, 0.8125, 0.8125, 0.875, 0.875, 0.90625, 0.90625, 0.9375, 0.9375, 0.96875, 0.96875, 1.0, 1.0], \"mode\": \"lines\", \"name\": \"Predictor\"}, {\"type\": \"scatter\", \"x\": [0.0, 0.0, 0.014705882352941176, 0.014705882352941176, 0.029411764705882353, 0.029411764705882353, 0.04411764705882353, 0.04411764705882353, 0.08823529411764706, 0.08823529411764706, 0.11764705882352941, 0.11764705882352941, 0.14705882352941177, 0.14705882352941177, 0.20588235294117646, 0.20588235294117646, 0.4264705882352941, 0.4264705882352941, 1.0], \"y\": [0.0, 0.0, 0.014705882352941176, 0.014705882352941176, 0.029411764705882353, 0.029411764705882353, 0.04411764705882353, 0.04411764705882353, 0.08823529411764706, 0.08823529411764706, 0.11764705882352941, 0.11764705882352941, 0.14705882352941177, 0.14705882352941177, 0.20588235294117646, 0.20588235294117646, 0.4264705882352941, 0.4264705882352941, 1.0], \"mode\": \"lines\", \"name\": \"Random\", \"line\": {\"dash\": \"dash\", \"color\": \"grey\"}}], {\"title\": \"ROC Curve for Ad Purchases\", \"xaxis\": {\"title\": \"False Positive Rate\"}, \"yaxis\": {\"title\": \"True Positive Rate\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under the ROC Curve (AUC) is 0.95\n"
     ]
    }
   ],
   "source": [
    "# Use sklearn to get us the tpr and fpr at different cutoffs\n",
    "tpr, fpr, _ = metrics.roc_curve(pred_df[\"Y_Values\"], pred_df[\"Probabilities\"])\n",
    "\n",
    "trace0 = go.Scatter(\n",
    "    x = tpr,\n",
    "    y = fpr,\n",
    "    mode = 'lines',\n",
    "    name = 'Predictor'\n",
    ")\n",
    "\n",
    "trace1 = go.Scatter(\n",
    "    x = tpr,\n",
    "    y = tpr,\n",
    "    mode='lines',\n",
    "    name='Random',\n",
    "    line=dict(\n",
    "        dash=\"dash\",\n",
    "        color=\"grey\")\n",
    ")\n",
    "\n",
    "data = [trace0, trace1]\n",
    "\n",
    "layout = dict(title = 'ROC Curve for Ad Purchases',\n",
    "              xaxis = dict(title = 'False Positive Rate'),\n",
    "              yaxis = dict(title = 'True Positive Rate'),\n",
    "              )\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "iplot(fig)\n",
    "auc = metrics.roc_auc_score(pred_df[\"Y_Values\"], pred_df[\"Probabilities\"])\n",
    "print(\"Area Under the ROC Curve (AUC) is %.2f\" % auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up is a precision-recall plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "mode": "lines",
         "name": "Predictor",
         "type": "scatter",
         "x": [
          1,
          0.96875,
          0.96875,
          0.96875,
          0.96875,
          0.96875,
          0.96875,
          0.96875,
          0.96875,
          0.96875,
          0.96875,
          0.96875,
          0.96875,
          0.96875,
          0.96875,
          0.96875,
          0.96875,
          0.9375,
          0.9375,
          0.9375,
          0.9375,
          0.9375,
          0.90625,
          0.90625,
          0.90625,
          0.875,
          0.875,
          0.875,
          0.84375,
          0.8125,
          0.8125,
          0.8125,
          0.8125,
          0.78125,
          0.75,
          0.75,
          0.71875,
          0.71875,
          0.6875,
          0.65625,
          0.625,
          0.59375,
          0.5625,
          0.53125,
          0.5,
          0.46875,
          0.4375,
          0.40625,
          0.375,
          0.34375,
          0.3125,
          0.28125,
          0.25,
          0.21875,
          0.1875,
          0.1875,
          0.15625,
          0.125,
          0.09375,
          0.0625,
          0.03125,
          0
         ],
         "y": [
          0.5245901639344263,
          0.5166666666666667,
          0.5254237288135594,
          0.5344827586206896,
          0.543859649122807,
          0.5535714285714286,
          0.5636363636363636,
          0.5740740740740741,
          0.5849056603773585,
          0.5961538461538461,
          0.6078431372549019,
          0.62,
          0.6326530612244898,
          0.6458333333333334,
          0.6595744680851063,
          0.6739130434782609,
          0.6888888888888889,
          0.6818181818181818,
          0.6976744186046512,
          0.7142857142857143,
          0.7317073170731707,
          0.75,
          0.7435897435897436,
          0.7631578947368421,
          0.7837837837837838,
          0.7777777777777778,
          0.8,
          0.8235294117647058,
          0.8181818181818182,
          0.8125,
          0.8387096774193549,
          0.8666666666666667,
          0.896551724137931,
          0.8928571428571429,
          0.8888888888888888,
          0.9230769230769231,
          0.92,
          0.9583333333333334,
          0.9565217391304348,
          0.9545454545454546,
          0.9523809523809523,
          0.95,
          0.9473684210526315,
          0.9444444444444444,
          0.9411764705882353,
          0.9375,
          0.9333333333333333,
          0.9285714285714286,
          0.9230769230769231,
          0.9166666666666666,
          0.9090909090909091,
          0.9,
          0.8888888888888888,
          0.875,
          0.8571428571428571,
          1,
          1,
          1,
          1,
          1,
          1,
          1
         ]
        }
       ],
       "layout": {
        "title": "Precision-Recall Curve for Ad Purchases",
        "xaxis": {
         "title": "Recall"
        },
        "yaxis": {
         "title": "Precision"
        }
       }
      },
      "text/html": [
       "<div id=\"7d6d9150-eb8e-42d0-9501-62aac24d6b0a\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"7d6d9150-eb8e-42d0-9501-62aac24d6b0a\", [{\"type\": \"scatter\", \"x\": [1.0, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.90625, 0.90625, 0.90625, 0.875, 0.875, 0.875, 0.84375, 0.8125, 0.8125, 0.8125, 0.8125, 0.78125, 0.75, 0.75, 0.71875, 0.71875, 0.6875, 0.65625, 0.625, 0.59375, 0.5625, 0.53125, 0.5, 0.46875, 0.4375, 0.40625, 0.375, 0.34375, 0.3125, 0.28125, 0.25, 0.21875, 0.1875, 0.1875, 0.15625, 0.125, 0.09375, 0.0625, 0.03125, 0.0], \"y\": [0.5245901639344263, 0.5166666666666667, 0.5254237288135594, 0.5344827586206896, 0.543859649122807, 0.5535714285714286, 0.5636363636363636, 0.5740740740740741, 0.5849056603773585, 0.5961538461538461, 0.6078431372549019, 0.62, 0.6326530612244898, 0.6458333333333334, 0.6595744680851063, 0.6739130434782609, 0.6888888888888889, 0.6818181818181818, 0.6976744186046512, 0.7142857142857143, 0.7317073170731707, 0.75, 0.7435897435897436, 0.7631578947368421, 0.7837837837837838, 0.7777777777777778, 0.8, 0.8235294117647058, 0.8181818181818182, 0.8125, 0.8387096774193549, 0.8666666666666667, 0.896551724137931, 0.8928571428571429, 0.8888888888888888, 0.9230769230769231, 0.92, 0.9583333333333334, 0.9565217391304348, 0.9545454545454546, 0.9523809523809523, 0.95, 0.9473684210526315, 0.9444444444444444, 0.9411764705882353, 0.9375, 0.9333333333333333, 0.9285714285714286, 0.9230769230769231, 0.9166666666666666, 0.9090909090909091, 0.9, 0.8888888888888888, 0.875, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], \"mode\": \"lines\", \"name\": \"Predictor\"}], {\"title\": \"Precision-Recall Curve for Ad Purchases\", \"xaxis\": {\"title\": \"Recall\"}, \"yaxis\": {\"title\": \"Precision\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"7d6d9150-eb8e-42d0-9501-62aac24d6b0a\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"7d6d9150-eb8e-42d0-9501-62aac24d6b0a\", [{\"type\": \"scatter\", \"x\": [1.0, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.90625, 0.90625, 0.90625, 0.875, 0.875, 0.875, 0.84375, 0.8125, 0.8125, 0.8125, 0.8125, 0.78125, 0.75, 0.75, 0.71875, 0.71875, 0.6875, 0.65625, 0.625, 0.59375, 0.5625, 0.53125, 0.5, 0.46875, 0.4375, 0.40625, 0.375, 0.34375, 0.3125, 0.28125, 0.25, 0.21875, 0.1875, 0.1875, 0.15625, 0.125, 0.09375, 0.0625, 0.03125, 0.0], \"y\": [0.5245901639344263, 0.5166666666666667, 0.5254237288135594, 0.5344827586206896, 0.543859649122807, 0.5535714285714286, 0.5636363636363636, 0.5740740740740741, 0.5849056603773585, 0.5961538461538461, 0.6078431372549019, 0.62, 0.6326530612244898, 0.6458333333333334, 0.6595744680851063, 0.6739130434782609, 0.6888888888888889, 0.6818181818181818, 0.6976744186046512, 0.7142857142857143, 0.7317073170731707, 0.75, 0.7435897435897436, 0.7631578947368421, 0.7837837837837838, 0.7777777777777778, 0.8, 0.8235294117647058, 0.8181818181818182, 0.8125, 0.8387096774193549, 0.8666666666666667, 0.896551724137931, 0.8928571428571429, 0.8888888888888888, 0.9230769230769231, 0.92, 0.9583333333333334, 0.9565217391304348, 0.9545454545454546, 0.9523809523809523, 0.95, 0.9473684210526315, 0.9444444444444444, 0.9411764705882353, 0.9375, 0.9333333333333333, 0.9285714285714286, 0.9230769230769231, 0.9166666666666666, 0.9090909090909091, 0.9, 0.8888888888888888, 0.875, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], \"mode\": \"lines\", \"name\": \"Predictor\"}], {\"title\": \"Precision-Recall Curve for Ad Purchases\", \"xaxis\": {\"title\": \"Recall\"}, \"yaxis\": {\"title\": \"Precision\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use sklearn to get us the tpr and fpr at different cutoffs\n",
    "precision, recall, _ = metrics.precision_recall_curve(pred_df[\"Y_Values\"], pred_df[\"Probabilities\"])\n",
    "\n",
    "trace0 = go.Scatter(\n",
    "    x = recall,\n",
    "    y = precision,\n",
    "    mode = 'lines',\n",
    "    name = 'Predictor'\n",
    ")\n",
    "\n",
    "data = [trace0]\n",
    "\n",
    "layout = dict(title = 'Precision-Recall Curve for Ad Purchases',\n",
    "              xaxis = dict(title = 'Recall'),\n",
    "              yaxis = dict(title = 'Precision'),\n",
    "              )\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "iplot(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
